{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1111749,"sourceType":"datasetVersion","datasetId":623329},{"sourceId":1706129,"sourceType":"datasetVersion","datasetId":1011404},{"sourceId":11219022,"sourceType":"datasetVersion","datasetId":7006240},{"sourceId":11219272,"sourceType":"datasetVersion","datasetId":7006413},{"sourceId":11250022,"sourceType":"datasetVersion","datasetId":7029845}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/nickxir12/MyCLIP_first_repo.git /kaggle/working/open-clip","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:32.190192Z","iopub.execute_input":"2025-04-02T10:33:32.190518Z","iopub.status.idle":"2025-04-02T10:33:32.373306Z","shell.execute_reply.started":"2025-04-02T10:33:32.190495Z","shell.execute_reply":"2025-04-02T10:33:32.372382Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path '/kaggle/working/open-clip' already exists and is not an empty directory.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# Step 1: Delete the old repo (if it exists)\n!rm -rf /kaggle/working/open-clip  \n\n# Step 2: Clone the latest version from GitHub\n!git clone https://github.com/nickxir12/MyCLIP_first_repo.git /kaggle/working/open-clip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:32.374845Z","iopub.execute_input":"2025-04-02T10:33:32.375253Z","iopub.status.idle":"2025-04-02T10:33:36.413677Z","shell.execute_reply.started":"2025-04-02T10:33:32.375217Z","shell.execute_reply":"2025-04-02T10:33:36.412662Z"}},"outputs":[{"name":"stdout","text":"Cloning into '/kaggle/working/open-clip'...\nremote: Enumerating objects: 3741, done.\u001b[K\nremote: Counting objects: 100% (3741/3741), done.\u001b[K\nremote: Compressing objects: 100% (1464/1464), done.\u001b[K\nremote: Total 3741 (delta 2271), reused 3641 (delta 2175), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (3741/3741), 16.76 MiB | 7.09 MiB/s, done.\nResolving deltas: 100% (2271/2271), done.\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"#!pip install open_clip_torch\n!pip install braceexpand\n!pip install webdataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:36.415758Z","iopub.execute_input":"2025-04-02T10:33:36.416067Z","iopub.status.idle":"2025-04-02T10:33:43.214273Z","shell.execute_reply.started":"2025-04-02T10:33:36.416042Z","shell.execute_reply":"2025-04-02T10:33:43.213396Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (0.1.7)\nRequirement already satisfied: webdataset in /usr/local/lib/python3.10/dist-packages (0.2.111)\nRequirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (from webdataset) (0.1.7)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from webdataset) (1.26.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from webdataset) (6.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->webdataset) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->webdataset) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->webdataset) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->webdataset) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->webdataset) (2024.2.0)\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"!pip install -r /kaggle/working/open-clip/requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:43.216015Z","iopub.execute_input":"2025-04-02T10:33:43.216259Z","iopub.status.idle":"2025-04-02T10:33:46.725670Z","shell.execute_reply.started":"2025-04-02T10:33:43.216237Z","shell.execute_reply":"2025-04-02T10:33:46.724598Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 1)) (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 2)) (0.20.1+cu121)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 3)) (2024.11.6)\nRequirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 4)) (6.3.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 5)) (4.67.1)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 6)) (0.29.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 7)) (0.4.5)\nRequirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 8)) (1.0.12)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (11.0.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->-r /kaggle/working/open-clip/requirements.txt (line 4)) (0.2.13)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (2.32.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2024.2.0)\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"import os\nimport sys\nsys.path.append(\"/kaggle/working/open-clip/src\")\nsys.path.append(\"/kaggle/working/open-clip/src/open_clip\")\nsys.path.append(\"/kaggle/working/open-clip/src/open_clip_train/my_metrics\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:46.726800Z","iopub.execute_input":"2025-04-02T10:33:46.727081Z","iopub.status.idle":"2025-04-02T10:33:46.731790Z","shell.execute_reply.started":"2025-04-02T10:33:46.727048Z","shell.execute_reply":"2025-04-02T10:33:46.731007Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# import importlib\n# import my_metrics\n# importlib.reload(my_metrics)\n# print(dir(my_metrics))  # Now should include 'batch', 'get_all_embeddings', etc.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:46.732700Z","iopub.execute_input":"2025-04-02T10:33:46.733015Z","iopub.status.idle":"2025-04-02T10:33:46.747900Z","shell.execute_reply.started":"2025-04-02T10:33:46.732993Z","shell.execute_reply":"2025-04-02T10:33:46.747003Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"from my_metrics import compute_consistency_score,evaluate_model\n\n#Does below work?\nfrom my_metrics import batch,get_all_embeddings,itm_eval,compute_consistency_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:46.748883Z","iopub.execute_input":"2025-04-02T10:33:46.749220Z","iopub.status.idle":"2025-04-02T10:33:46.761754Z","shell.execute_reply.started":"2025-04-02T10:33:46.749189Z","shell.execute_reply":"2025-04-02T10:33:46.760963Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"import open_clip\nimport open_clip_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:46.764277Z","iopub.execute_input":"2025-04-02T10:33:46.764493Z","iopub.status.idle":"2025-04-02T10:33:46.779228Z","shell.execute_reply.started":"2025-04-02T10:33:46.764475Z","shell.execute_reply":"2025-04-02T10:33:46.778510Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nimport json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:46.780705Z","iopub.execute_input":"2025-04-02T10:33:46.780962Z","iopub.status.idle":"2025-04-02T10:33:46.796335Z","shell.execute_reply.started":"2025-04-02T10:33:46.780933Z","shell.execute_reply":"2025-04-02T10:33:46.795692Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"import torch\nimport os\nimport open_clip\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:46.797265Z","iopub.execute_input":"2025-04-02T10:33:46.797555Z","iopub.status.idle":"2025-04-02T10:33:46.811767Z","shell.execute_reply.started":"2025-04-02T10:33:46.797527Z","shell.execute_reply":"2025-04-02T10:33:46.811061Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"#open_clip.list_pretrained()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:46.812466Z","iopub.execute_input":"2025-04-02T10:33:46.812651Z","iopub.status.idle":"2025-04-02T10:33:46.829663Z","shell.execute_reply.started":"2025-04-02T10:33:46.812633Z","shell.execute_reply":"2025-04-02T10:33:46.829011Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"#                Preparing train datasaet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:46.830542Z","iopub.execute_input":"2025-04-02T10:33:46.830767Z","iopub.status.idle":"2025-04-02T10:33:46.846328Z","shell.execute_reply.started":"2025-04-02T10:33:46.830742Z","shell.execute_reply":"2025-04-02T10:33:46.845671Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"import json\nimport pandas as pd\n\n# Load Karpathy JSON file\nkarpathy_json_path = \"/kaggle/input/karpathy-splits/dataset_flickr30k.json\"\nwith open(karpathy_json_path, \"r\") as f:\n    karpathy_data = json.load(f)\n\n# Extract training set\ntrain_data = [item for item in karpathy_data[\"images\"] if item[\"split\"] == \"train\"]\n\n# Prepare data for CSV\ntrain_records = []\nfor item in train_data:\n    img_filename = f\"/kaggle/input/flickr30k/Images/{item['filename']}\"\n    for sentence in item[\"sentences\"]:\n        caption = sentence[\"raw\"]\n        train_records.append({\"image\": img_filename, \"caption\": caption})\n\n# Convert to DataFrame\ndf_train = pd.DataFrame(train_records)\n\n# Save to CSV (formatted properly)\ncsv_path = \"/kaggle/working/train_data_karpathy.csv\"\ndf_train.to_csv(csv_path, index=True, index_label=\"id\")\n\nprint(f\"✅ CSV file saved at: {csv_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:46.847295Z","iopub.execute_input":"2025-04-02T10:33:46.847597Z","iopub.status.idle":"2025-04-02T10:33:49.181158Z","shell.execute_reply.started":"2025-04-02T10:33:46.847566Z","shell.execute_reply":"2025-04-02T10:33:49.180105Z"}},"outputs":[{"name":"stdout","text":"✅ CSV file saved at: /kaggle/working/train_data_karpathy.csv\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:49.182185Z","iopub.execute_input":"2025-04-02T10:33:49.182514Z","iopub.status.idle":"2025-04-02T10:33:49.190669Z","shell.execute_reply.started":"2025-04-02T10:33:49.182491Z","shell.execute_reply":"2025-04-02T10:33:49.189963Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"                                           image  \\\n0  /kaggle/input/flickr30k/Images/1000092795.jpg   \n1  /kaggle/input/flickr30k/Images/1000092795.jpg   \n2  /kaggle/input/flickr30k/Images/1000092795.jpg   \n3  /kaggle/input/flickr30k/Images/1000092795.jpg   \n4  /kaggle/input/flickr30k/Images/1000092795.jpg   \n\n                                             caption  \n0  Two young guys with shaggy hair look at their ...  \n1  Two young, White males are outside near many b...  \n2    Two men in green shirts are standing in a yard.  \n3        A man in a blue shirt standing in a garden.  \n4             Two friends enjoy time spent together.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n      <td>Two young guys with shaggy hair look at their ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n      <td>Two young, White males are outside near many b...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n      <td>Two men in green shirts are standing in a yard.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n      <td>A man in a blue shirt standing in a garden.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n      <td>Two friends enjoy time spent together.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"karpathy_json_path = \"/kaggle/input/karpathy-splits/dataset_flickr30k.json\"\nwith open(karpathy_json_path, \"r\") as f:\n    karpathy_data = json.load(f)\n\n# Extract test set\ntest_data = [item for item in karpathy_data[\"images\"] if item[\"split\"] == \"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:49.191529Z","iopub.execute_input":"2025-04-02T10:33:49.191865Z","iopub.status.idle":"2025-04-02T10:33:50.937459Z","shell.execute_reply.started":"2025-04-02T10:33:49.191831Z","shell.execute_reply":"2025-04-02T10:33:50.936624Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:50.938320Z","iopub.execute_input":"2025-04-02T10:33:50.938627Z","iopub.status.idle":"2025-04-02T10:33:50.943989Z","shell.execute_reply.started":"2025-04-02T10:33:50.938595Z","shell.execute_reply":"2025-04-02T10:33:50.943141Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"#Standard loading\n# model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n# model = model.to(device)\n# model.eval()  # model in train mode by default, impacts some models with BatchNorm or stochastic depth active\n# tokenizer = open_clip.get_tokenizer('ViT-B-32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:50.945024Z","iopub.execute_input":"2025-04-02T10:33:50.945349Z","iopub.status.idle":"2025-04-02T10:33:50.960454Z","shell.execute_reply.started":"2025-04-02T10:33:50.945317Z","shell.execute_reply":"2025-04-02T10:33:50.959674Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# # FOR CYCLIP PRE TRAINED THAT I HAVE DOWNLOADED LOCALLY\n# model_clip_3M, _, preprocess = open_clip.create_model_and_transforms(\n#     model_name=\"RN50\",\n#     pretrained=None,  # Don't load default weights\n#     precision='fp32', # or 'amp' for mixed precision\n#     device=device\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:50.961349Z","iopub.execute_input":"2025-04-02T10:33:50.961612Z","iopub.status.idle":"2025-04-02T10:33:50.979421Z","shell.execute_reply.started":"2025-04-02T10:33:50.961588Z","shell.execute_reply":"2025-04-02T10:33:50.978549Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"# # Load the checkpoint - OG CLIP - 3M\n# ckpt = torch.load(\"/kaggle/input/clip-3m-from-cyclip/clip-3M.pt/best.pt\", map_location=device)\n# state_dict = ckpt[\"state_dict\"]\n\n# # Remove 'module.' prefix from keys\n# new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n\n# # Load into your model\n# model_clip_3M.load_state_dict(new_state_dict)\n# model_clip_3M.to(device)\n# model_clip_3M.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:50.980264Z","iopub.execute_input":"2025-04-02T10:33:50.980532Z","iopub.status.idle":"2025-04-02T10:33:50.994440Z","shell.execute_reply.started":"2025-04-02T10:33:50.980511Z","shell.execute_reply":"2025-04-02T10:33:50.993656Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# FOR CYCLIP PRE TRAINED THAT I HAVE DOWNLOADED LOCALLY\n# model_Cyclip_3M, _, preprocess = open_clip.create_model_and_transforms(\n#     model_name=\"RN50\",\n#     pretrained=None,  # Don't load default weights\n#     precision='fp32', # or 'amp' for mixed precision\n#     device=device\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:50.995241Z","iopub.execute_input":"2025-04-02T10:33:50.995439Z","iopub.status.idle":"2025-04-02T10:33:51.010751Z","shell.execute_reply.started":"2025-04-02T10:33:50.995421Z","shell.execute_reply":"2025-04-02T10:33:51.010127Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"# # Load the checkpoint - CY CLIP - 3M\n# ckpt = torch.load(\"/kaggle/input/cyclip-3m/CYCLIP-3M_best.pt\", map_location=device)\n# state_dict = ckpt[\"state_dict\"]\n\n# # Remove 'module.' prefix from keys\n# new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n\n# # Load into your model\n# model_Cyclip_3M.load_state_dict(new_state_dict)\n# model_Cyclip_3M.to(device)\n# model_Cyclip_3M.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:51.011478Z","iopub.execute_input":"2025-04-02T10:33:51.011748Z","iopub.status.idle":"2025-04-02T10:33:51.025779Z","shell.execute_reply.started":"2025-04-02T10:33:51.011728Z","shell.execute_reply":"2025-04-02T10:33:51.025050Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"#Tokenizer for my models\ntokenizer = open_clip.get_tokenizer('RN50')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:51.026592Z","iopub.execute_input":"2025-04-02T10:33:51.026814Z","iopub.status.idle":"2025-04-02T10:33:51.155040Z","shell.execute_reply.started":"2025-04-02T10:33:51.026795Z","shell.execute_reply":"2025-04-02T10:33:51.154276Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"#FOR CYCLIP PRE TRAINED THAT I HAVE DOWNLOADED LOCALLY\nmodel_clip_final, _, preprocess = open_clip.create_model_and_transforms(\n    model_name=\"RN50\",\n    pretrained=None,  # Don't load default weights\n    precision='fp32', # or 'amp' for mixed precision\n    device=device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:51.158496Z","iopub.execute_input":"2025-04-02T10:33:51.158708Z","iopub.status.idle":"2025-04-02T10:33:52.566877Z","shell.execute_reply.started":"2025-04-02T10:33:51.158689Z","shell.execute_reply":"2025-04-02T10:33:52.566202Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"# Load the checkpoint - CLIP - Final\nckpt = torch.load(\"/kaggle/input/clip-final/clip_best.pt\", map_location=device)\nstate_dict = ckpt[\"state_dict\"]\n\n# Remove 'module.' prefix from keys\nnew_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n\n# Load into your model\nmodel_clip_final.load_state_dict(new_state_dict)\nmodel_clip_final.to(device)\nmodel_clip_final.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:52.568639Z","iopub.execute_input":"2025-04-02T10:33:52.568850Z","iopub.status.idle":"2025-04-02T10:33:53.655381Z","shell.execute_reply.started":"2025-04-02T10:33:52.568833Z","shell.execute_reply":"2025-04-02T10:33:53.654573Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-62-74080bc77d25>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(\"/kaggle/input/clip-final/clip_best.pt\", map_location=device)\n","output_type":"stream"},{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"CLIP(\n  (visual): ModifiedResNet(\n    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act2): ReLU(inplace=True)\n    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (attnpool): AttentionPool2d(\n      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n    )\n  )\n  (transformer): Transformer(\n    (resblocks): ModuleList(\n      (0-11): 12 x ResidualAttentionBlock(\n        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (ls_1): Identity()\n        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n          (gelu): GELU(approximate='none')\n          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (ls_2): Identity()\n      )\n    )\n  )\n  (token_embedding): Embedding(49408, 512)\n  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n)"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"torch.save(new_state_dict, '/kaggle/working/clip_final.pt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:53.656423Z","iopub.execute_input":"2025-04-02T10:33:53.656699Z","iopub.status.idle":"2025-04-02T10:33:54.667309Z","shell.execute_reply.started":"2025-04-02T10:33:53.656676Z","shell.execute_reply":"2025-04-02T10:33:54.666352Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"#FOR CYCLIP PRE TRAINED THAT I HAVE DOWNLOADED LOCALLY\nmodel_Cyclip_final, _, preprocess = open_clip.create_model_and_transforms(\n    model_name=\"RN50\",\n    pretrained=None,  # Don't load default weights\n    precision='fp32', # or 'amp' for mixed precision\n    device=device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:54.668565Z","iopub.execute_input":"2025-04-02T10:33:54.668893Z","iopub.status.idle":"2025-04-02T10:33:56.049712Z","shell.execute_reply.started":"2025-04-02T10:33:54.668862Z","shell.execute_reply":"2025-04-02T10:33:56.048763Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# Load the checkpoint - CY CLIP - Final\nckpt = torch.load(\"/kaggle/input/cyclip-final/cyclip_best.pt\", map_location=device)\nstate_dict = ckpt[\"state_dict\"]\n\n# Remove 'module.' prefix from keys\nnew_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n\n# Load into your model\nmodel_Cyclip_final.load_state_dict(new_state_dict)\nmodel_Cyclip_final.to(device)\nmodel_Cyclip_final.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:56.050617Z","iopub.execute_input":"2025-04-02T10:33:56.050886Z","iopub.status.idle":"2025-04-02T10:33:57.177096Z","shell.execute_reply.started":"2025-04-02T10:33:56.050857Z","shell.execute_reply":"2025-04-02T10:33:57.176277Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-65-681b61487b99>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(\"/kaggle/input/cyclip-final/cyclip_best.pt\", map_location=device)\n","output_type":"stream"},{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"CLIP(\n  (visual): ModifiedResNet(\n    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act2): ReLU(inplace=True)\n    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (attnpool): AttentionPool2d(\n      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n    )\n  )\n  (transformer): Transformer(\n    (resblocks): ModuleList(\n      (0-11): 12 x ResidualAttentionBlock(\n        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (ls_1): Identity()\n        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n          (gelu): GELU(approximate='none')\n          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (ls_2): Identity()\n      )\n    )\n  )\n  (token_embedding): Embedding(49408, 512)\n  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n)"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"torch.save(new_state_dict, '/kaggle/working/Cyclip_final.pt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:57.177881Z","iopub.execute_input":"2025-04-02T10:33:57.178157Z","iopub.status.idle":"2025-04-02T10:33:58.195730Z","shell.execute_reply.started":"2025-04-02T10:33:57.178135Z","shell.execute_reply":"2025-04-02T10:33:58.194750Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"# open_clip.list_pretrained()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:58.197031Z","iopub.execute_input":"2025-04-02T10:33:58.197382Z","iopub.status.idle":"2025-04-02T10:33:58.201530Z","shell.execute_reply.started":"2025-04-02T10:33:58.197345Z","shell.execute_reply":"2025-04-02T10:33:58.200523Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"#                Models loaded are model_Cyclip_final and model_clip_final\n#                Will further fine them below\n                    # Will fine tune\n                    #     --> as usual\n                    #     --> with Dino regularizor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:58.202529Z","iopub.execute_input":"2025-04-02T10:33:58.202854Z","iopub.status.idle":"2025-04-02T10:33:58.223670Z","shell.execute_reply.started":"2025-04-02T10:33:58.202825Z","shell.execute_reply":"2025-04-02T10:33:58.222769Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"#          TO FINE TUNE vol1\n# !python /kaggle/working/open-clip/src/open_clip_train/main.py \\\n#     --train-data /kaggle/working/train_data_karpathy.csv \\\n#     --name 'dino_fine_tuned_Clip_10_epochs' \\\n#     --dataset-type csv \\\n#     --csv-img-key image \\\n#     --csv-caption-key caption \\\n#     --csv-separator \",\" \\\n#     --model RN50  \\\n#     --pretrained /kaggle/working/clip_final.pt \\\n#     --batch-size 48 \\\n#     --lr 5e-6 \\\n#     --warmup 1000 \\\n#     --epochs 10 \\\n#     --lr-scheduler cosine \\\n#     --precision amp \\\n#     --workers 4 \\\n#     --logs \"logs\" \\\n#     --logs \"checkpoints\" \\\n#     --save-frequency 1 \\\n#     --seed 42 \\\n#     --lambda_dino 0.25 \\\n#     --alpha 0  \\\n#     --use_dino_reg ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:58.224418Z","iopub.execute_input":"2025-04-02T10:33:58.224620Z","iopub.status.idle":"2025-04-02T10:33:58.239205Z","shell.execute_reply.started":"2025-04-02T10:33:58.224603Z","shell.execute_reply":"2025-04-02T10:33:58.238476Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"# import torch\n# import open_clip\n\n# # Path to your trained checkpoint\n# checkpoint_path = \"checkpoints/dino_fine_tuned_Clip_10_epochs/checkpoints/epoch_10.pt\"\n\n# # 1. Create the model architecture from scratch (without loading pretrained weights)\n# model_dino_fine_tuned_Clip_10_epochs, preprocess_ft, preprocess_val = open_clip.create_model_and_transforms(\n#     \"RN50\", pretrained=None\n# )\n\n# # 2. Load the trained checkpoint manually\n# checkpoint = torch.load(checkpoint_path, map_location=\"cpu\",weights_only=True)\n\n# # If the state_dict is nested under a key (like \"state_dict\"), adjust accordingly\n# if \"state_dict\" in checkpoint:\n#     checkpoint = checkpoint[\"state_dict\"]\n\n# # Load checkpoint weights into model\n# model_dino_fine_tuned_Clip_10_epochs.load_state_dict(checkpoint, strict=False)  # Use strict=False to avoid missing keys error\n\n# # 3. Move model to GPU (if available)\n# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# model_dino_fine_tuned_Clip_10_epochs = model_dino_fine_tuned_Clip_10_epochs.to(device)\n# model_dino_fine_tuned_Clip_10_epochs.eval()\n# print(\"Model loaded successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:58.239998Z","iopub.execute_input":"2025-04-02T10:33:58.240247Z","iopub.status.idle":"2025-04-02T10:33:58.257125Z","shell.execute_reply.started":"2025-04-02T10:33:58.240214Z","shell.execute_reply":"2025-04-02T10:33:58.256483Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"# TO LOAD EPOCH 6 and EPOCH 10\n#LOAD EPOCH 10 at model_dino_fine_tuned_Clip_10_epochs\n\nmodel_dino_fine_tuned_Clip_10_epochs, _, preprocess = open_clip.create_model_and_transforms(\n    model_name=\"RN50\",\n    pretrained=None,  # Don't load default weights\n    precision='fp32', # or 'amp' for mixed precision\n    device=device\n)\n\n# Load from the checkpoint\nckpt = torch.load(\"/kaggle/input/10-epochs/model_dino_fine_tuned_Clip_10_epochs.pt\", map_location=device)\nstate_dict = ckpt[\"state_dict\"]\n\n# Remove 'module.' prefix from keys\nnew_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n\n# Load into your model\nmodel_dino_fine_tuned_Clip_10_epochs.load_state_dict(new_state_dict)\nmodel_dino_fine_tuned_Clip_10_epochs.to(device)\nmodel_dino_fine_tuned_Clip_10_epochs.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:33:58.257958Z","iopub.execute_input":"2025-04-02T10:33:58.258204Z","iopub.status.idle":"2025-04-02T10:34:00.782034Z","shell.execute_reply.started":"2025-04-02T10:33:58.258178Z","shell.execute_reply":"2025-04-02T10:34:00.780830Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-71-7c329cfe231e>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(\"/kaggle/input/10-epochs/model_dino_fine_tuned_Clip_10_epochs.pt\", map_location=device)\n","output_type":"stream"},{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"CLIP(\n  (visual): ModifiedResNet(\n    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act2): ReLU(inplace=True)\n    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (attnpool): AttentionPool2d(\n      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n    )\n  )\n  (transformer): Transformer(\n    (resblocks): ModuleList(\n      (0-11): 12 x ResidualAttentionBlock(\n        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (ls_1): Identity()\n        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n          (gelu): GELU(approximate='none')\n          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (ls_2): Identity()\n      )\n    )\n  )\n  (token_embedding): Embedding(49408, 512)\n  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n)"},"metadata":{}}],"execution_count":71},{"cell_type":"code","source":"#          TO FINE TUNE vol2 (4 epochs remaning)\n!python /kaggle/working/open-clip/src/open_clip_train/main.py \\\n    --train-data /kaggle/working/train_data_karpathy.csv \\\n    --name 'og_fine_tuned_Clip_10_epochs' \\\n    --dataset-type csv \\\n    --csv-img-key image \\\n    --csv-caption-key caption \\\n    --csv-separator \",\" \\\n    --model RN50  \\\n    --pretrained /kaggle/input/10-epochs/model_og_fine_tuned_Clip_6_epochs.pt \\\n    --batch-size 48 \\\n    --lr 5e-6 \\\n    --warmup 1000 \\\n    --epochs 4 \\\n    --lr-scheduler cosine \\\n    --precision amp \\\n    --workers 4 \\\n    --logs \"logs\" \\\n    --logs \"checkpoints\" \\\n    --save-frequency 1 \\\n    --seed 42 \\\n\n    #--lambda_dino 0.25 \\\n    #--use_soft_labels \\\n    #--soft_temprature 0.05 \\\n    #--alpha 0  \\\n    #use_dino_reg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T10:37:10.678510Z","iopub.execute_input":"2025-04-02T10:37:10.678886Z","iopub.status.idle":"2025-04-02T11:51:04.450138Z","shell.execute_reply.started":"2025-04-02T10:37:10.678854Z","shell.execute_reply":"2025-04-02T11:51:04.448865Z"}},"outputs":[{"name":"stdout","text":"2025-04-02 10:37:14.297647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-02 10:37:14.317328: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-02 10:37:14.323416: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nUsing device: cuda\n['/kaggle/working/open-clip/src/open_clip_train/main.py', '--train-data', '/kaggle/working/train_data_karpathy.csv', '--name', 'og_fine_tuned_Clip_10_epochs', '--dataset-type', 'csv', '--csv-img-key', 'image', '--csv-caption-key', 'caption', '--csv-separator', ',', '--model', 'RN50', '--pretrained', '/kaggle/input/10-epochs/model_og_fine_tuned_Clip_6_epochs.pt', '--batch-size', '48', '--lr', '5e-6', '--warmup', '1000', '--epochs', '4', '--lr-scheduler', 'cosine', '--precision', 'amp', '--workers', '4', '--logs', 'logs', '--logs', 'checkpoints', '--save-frequency', '1', '--seed', '42']\nuse_soft_labels: False\nalpha: 0.5\n2025-04-02,10:37:19 | INFO | Running with a single process. Device cuda.\n2025-04-02,10:37:19 | INFO | Loaded RN50 model config.\n2025-04-02,10:37:20 | INFO | Loading pretrained RN50 weights (/kaggle/input/10-epochs/model_og_fine_tuned_Clip_6_epochs.pt).\n2025-04-02,10:37:27 | INFO | Model:\n2025-04-02,10:37:27 | INFO | CLIP(\n  (visual): ModifiedResNet(\n    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act2): ReLU(inplace=True)\n    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (attnpool): AttentionPool2d(\n      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n    )\n  )\n  (transformer): Transformer(\n    (resblocks): ModuleList(\n      (0-11): 12 x ResidualAttentionBlock(\n        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (ls_1): Identity()\n        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n          (gelu): GELU(approximate='none')\n          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (ls_2): Identity()\n      )\n    )\n  )\n  (token_embedding): Embedding(49408, 512)\n  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n)\n2025-04-02,10:37:27 | INFO | Params:\n2025-04-02,10:37:27 | INFO |   accum_freq: 1\n2025-04-02,10:37:27 | INFO |   alpha: 0.5\n2025-04-02,10:37:27 | INFO |   aug_cfg: {}\n2025-04-02,10:37:27 | INFO |   batch_size: 48\n2025-04-02,10:37:27 | INFO |   beta1: 0.9\n2025-04-02,10:37:27 | INFO |   beta2: 0.999\n2025-04-02,10:37:27 | INFO |   cache_dir: None\n2025-04-02,10:37:27 | INFO |   checkpoint_path: checkpoints/og_fine_tuned_Clip_10_epochs/checkpoints\n2025-04-02,10:37:27 | INFO |   coca_caption_loss_weight: 2.0\n2025-04-02,10:37:27 | INFO |   coca_contrastive_loss_weight: 1.0\n2025-04-02,10:37:27 | INFO |   copy_codebase: False\n2025-04-02,10:37:27 | INFO |   csv_caption_key: caption\n2025-04-02,10:37:27 | INFO |   csv_img_key: image\n2025-04-02,10:37:27 | INFO |   csv_separator: ,\n2025-04-02,10:37:27 | INFO |   dataset_resampled: False\n2025-04-02,10:37:27 | INFO |   dataset_type: csv\n2025-04-02,10:37:27 | INFO |   ddp_static_graph: False\n2025-04-02,10:37:27 | INFO |   debug: False\n2025-04-02,10:37:27 | INFO |   delete_previous_checkpoint: False\n2025-04-02,10:37:27 | INFO |   device: cuda\n2025-04-02,10:37:27 | INFO |   dist_backend: None\n2025-04-02,10:37:27 | INFO |   dist_url: None\n2025-04-02,10:37:27 | INFO |   distill: False\n2025-04-02,10:37:27 | INFO |   distill_model: None\n2025-04-02,10:37:27 | INFO |   distill_pretrained: None\n2025-04-02,10:37:27 | INFO |   distributed: False\n2025-04-02,10:37:27 | INFO |   enforce_to_text: False\n2025-04-02,10:37:27 | INFO |   epochs: 4\n2025-04-02,10:37:27 | INFO |   epochs_cooldown: None\n2025-04-02,10:37:27 | INFO |   eps: 1e-08\n2025-04-02,10:37:27 | INFO |   force_custom_text: False\n2025-04-02,10:37:27 | INFO |   force_image_size: None\n2025-04-02,10:37:27 | INFO |   force_patch_dropout: None\n2025-04-02,10:37:27 | INFO |   force_quick_gelu: False\n2025-04-02,10:37:27 | INFO |   gather_with_grad: False\n2025-04-02,10:37:27 | INFO |   grad_checkpointing: False\n2025-04-02,10:37:27 | INFO |   grad_clip_norm: None\n2025-04-02,10:37:27 | INFO |   horovod: False\n2025-04-02,10:37:27 | INFO |   image_interpolation: None\n2025-04-02,10:37:27 | INFO |   image_mean: None\n2025-04-02,10:37:27 | INFO |   image_resize_mode: None\n2025-04-02,10:37:27 | INFO |   image_std: None\n2025-04-02,10:37:27 | INFO |   imagenet_v2: None\n2025-04-02,10:37:27 | INFO |   imagenet_val: None\n2025-04-02,10:37:27 | INFO |   lambda_dino: 0.1\n2025-04-02,10:37:27 | INFO |   local_loss: False\n2025-04-02,10:37:27 | INFO |   local_rank: 0\n2025-04-02,10:37:27 | INFO |   lock_image: False\n2025-04-02,10:37:27 | INFO |   lock_image_freeze_bn_stats: False\n2025-04-02,10:37:27 | INFO |   lock_image_unlocked_groups: 0\n2025-04-02,10:37:27 | INFO |   lock_text: False\n2025-04-02,10:37:27 | INFO |   lock_text_freeze_layer_norm: False\n2025-04-02,10:37:27 | INFO |   lock_text_unlocked_layers: 0\n2025-04-02,10:37:27 | INFO |   log_every_n_steps: 100\n2025-04-02,10:37:27 | INFO |   log_level: 20\n2025-04-02,10:37:27 | INFO |   log_local: False\n2025-04-02,10:37:27 | INFO |   log_path: checkpoints/og_fine_tuned_Clip_10_epochs/out.log\n2025-04-02,10:37:27 | INFO |   logs: checkpoints\n2025-04-02,10:37:27 | INFO |   loss_dist_impl: None\n2025-04-02,10:37:27 | INFO |   lr: 5e-06\n2025-04-02,10:37:27 | INFO |   lr_cooldown_end: 0.0\n2025-04-02,10:37:27 | INFO |   lr_cooldown_power: 1.0\n2025-04-02,10:37:27 | INFO |   lr_scheduler: cosine\n2025-04-02,10:37:27 | INFO |   model: RN50\n2025-04-02,10:37:27 | INFO |   momentum: None\n2025-04-02,10:37:27 | INFO |   name: og_fine_tuned_Clip_10_epochs\n2025-04-02,10:37:27 | INFO |   no_set_device_rank: False\n2025-04-02,10:37:27 | INFO |   opt: adamw\n2025-04-02,10:37:27 | INFO |   precision: amp\n2025-04-02,10:37:27 | INFO |   pretrained: /kaggle/input/10-epochs/model_og_fine_tuned_Clip_6_epochs.pt\n2025-04-02,10:37:27 | INFO |   pretrained_image: False\n2025-04-02,10:37:27 | INFO |   rank: 0\n2025-04-02,10:37:27 | INFO |   remote_sync: None\n2025-04-02,10:37:27 | INFO |   remote_sync_frequency: 300\n2025-04-02,10:37:27 | INFO |   remote_sync_protocol: s3\n2025-04-02,10:37:27 | INFO |   report_to: \n2025-04-02,10:37:27 | INFO |   resume: None\n2025-04-02,10:37:27 | INFO |   save_frequency: 1\n2025-04-02,10:37:27 | INFO |   save_most_recent: False\n2025-04-02,10:37:27 | INFO |   seed: 42\n2025-04-02,10:37:27 | INFO |   siglip: False\n2025-04-02,10:37:27 | INFO |   skip_scheduler: False\n2025-04-02,10:37:27 | INFO |   soft_temprature: 0.02\n2025-04-02,10:37:27 | INFO |   tensorboard: False\n2025-04-02,10:37:27 | INFO |   tensorboard_path: \n2025-04-02,10:37:27 | INFO |   torchcompile: False\n2025-04-02,10:37:27 | INFO |   torchscript: False\n2025-04-02,10:37:27 | INFO |   trace: False\n2025-04-02,10:37:27 | INFO |   train_data: /kaggle/working/train_data_karpathy.csv\n2025-04-02,10:37:27 | INFO |   train_data_upsampling_factors: None\n2025-04-02,10:37:27 | INFO |   train_num_samples: None\n2025-04-02,10:37:27 | INFO |   use_bn_sync: False\n2025-04-02,10:37:27 | INFO |   use_bnb_linear: None\n2025-04-02,10:37:27 | INFO |   use_dino_reg: False\n2025-04-02,10:37:27 | INFO |   use_soft_labels: False\n2025-04-02,10:37:27 | INFO |   val_data: None\n2025-04-02,10:37:27 | INFO |   val_frequency: 1\n2025-04-02,10:37:27 | INFO |   val_num_samples: None\n2025-04-02,10:37:27 | INFO |   wandb: False\n2025-04-02,10:37:27 | INFO |   wandb_notes: \n2025-04-02,10:37:27 | INFO |   wandb_project_name: open-clip\n2025-04-02,10:37:27 | INFO |   warmup: 1000\n2025-04-02,10:37:27 | INFO |   wd: 0.2\n2025-04-02,10:37:27 | INFO |   workers: 4\n2025-04-02,10:37:27 | INFO |   world_size: 1\n2025-04-02,10:37:27 | INFO |   zeroshot_frequency: 2\n2025-04-02,10:37:27 | INFO | Created AdamW (adamw) optimizer: lr: 5e-06, betas: (0.9, 0.999), eps: 1e-08, weight_decay: 0.2, amsgrad: False, foreach: None, maximize: False, capturable: False, differentiable: False, fused: None\n2025-04-02,10:37:27 | INFO | Start epoch 0\n2025-04-02,10:37:34 | INFO | Train Epoch: 0 [    48/145000 (0%)] Data (t): 1.240 Batch (t): 6.607, 7.26493/s, 7.26493/s/gpu LR: 0.000000 Logit Scale: 73.631 Original_clip_loss: 0.070200 (0.070200) Loss: 0.070200 (0.070200)\n2025-04-02,10:38:11 | INFO | Train Epoch: 0 [  4848/145000 (3%)] Data (t): 0.001 Batch (t): 0.368, 128.818/s, 128.818/s/gpu LR: 0.000001 Logit Scale: 73.631 Original_clip_loss: 0.14157 (0.10589) Loss: 0.14157 (0.10589)\n2025-04-02,10:38:47 | INFO | Train Epoch: 0 [  9648/145000 (7%)] Data (t): 0.001 Batch (t): 0.364, 133.598/s, 133.598/s/gpu LR: 0.000001 Logit Scale: 73.631 Original_clip_loss: 0.087312 (0.099695) Loss: 0.087312 (0.099695)\n2025-04-02,10:39:23 | INFO | Train Epoch: 0 [ 14448/145000 (10%)] Data (t): 0.001 Batch (t): 0.362, 131.406/s, 131.406/s/gpu LR: 0.000002 Logit Scale: 73.634 Original_clip_loss: 0.22389 (0.13075) Loss: 0.22389 (0.13075)\n2025-04-02,10:40:00 | INFO | Train Epoch: 0 [ 19248/145000 (13%)] Data (t): 0.001 Batch (t): 0.365, 131.832/s, 131.832/s/gpu LR: 0.000002 Logit Scale: 73.639 Original_clip_loss: 0.14103 (0.13280) Loss: 0.14103 (0.13280)\n2025-04-02,10:40:36 | INFO | Train Epoch: 0 [ 24048/145000 (17%)] Data (t): 0.001 Batch (t): 0.364, 132.479/s, 132.479/s/gpu LR: 0.000003 Logit Scale: 73.642 Original_clip_loss: 0.086632 (0.12511) Loss: 0.086632 (0.12511)\n2025-04-02,10:41:13 | INFO | Train Epoch: 0 [ 28848/145000 (20%)] Data (t): 0.001 Batch (t): 0.364, 132.082/s, 132.082/s/gpu LR: 0.000003 Logit Scale: 73.647 Original_clip_loss: 0.17973 (0.13291) Loss: 0.17973 (0.13291)\n2025-04-02,10:41:49 | INFO | Train Epoch: 0 [ 33648/145000 (23%)] Data (t): 0.001 Batch (t): 0.364, 131.679/s, 131.679/s/gpu LR: 0.000004 Logit Scale: 73.656 Original_clip_loss: 0.098340 (0.12859) Loss: 0.098340 (0.12859)\n2025-04-02,10:42:26 | INFO | Train Epoch: 0 [ 38448/145000 (27%)] Data (t): 0.001 Batch (t): 0.365, 131.864/s, 131.864/s/gpu LR: 0.000004 Logit Scale: 73.664 Original_clip_loss: 0.065854 (0.12162) Loss: 0.065854 (0.12162)\n2025-04-02,10:43:02 | INFO | Train Epoch: 0 [ 43248/145000 (30%)] Data (t): 0.001 Batch (t): 0.364, 131.536/s, 131.536/s/gpu LR: 0.000005 Logit Scale: 73.672 Original_clip_loss: 0.19991 (0.12945) Loss: 0.19991 (0.12945)\n2025-04-02,10:43:38 | INFO | Train Epoch: 0 [ 48048/145000 (33%)] Data (t): 0.001 Batch (t): 0.364, 132.602/s, 132.602/s/gpu LR: 0.000005 Logit Scale: 73.683 Original_clip_loss: 0.045929 (0.12186) Loss: 0.045929 (0.12186)\n2025-04-02,10:44:15 | INFO | Train Epoch: 0 [ 52848/145000 (36%)] Data (t): 0.001 Batch (t): 0.364, 131.833/s, 131.833/s/gpu LR: 0.000005 Logit Scale: 73.694 Original_clip_loss: 0.17176 (0.12601) Loss: 0.17176 (0.12601)\n2025-04-02,10:44:51 | INFO | Train Epoch: 0 [ 57648/145000 (40%)] Data (t): 0.001 Batch (t): 0.364, 132.446/s, 132.446/s/gpu LR: 0.000005 Logit Scale: 73.705 Original_clip_loss: 0.15377 (0.12815) Loss: 0.15377 (0.12815)\n2025-04-02,10:45:28 | INFO | Train Epoch: 0 [ 62448/145000 (43%)] Data (t): 0.001 Batch (t): 0.364, 131.663/s, 131.663/s/gpu LR: 0.000005 Logit Scale: 73.716 Original_clip_loss: 0.056375 (0.12302) Loss: 0.056375 (0.12302)\n2025-04-02,10:46:04 | INFO | Train Epoch: 0 [ 67248/145000 (46%)] Data (t): 0.001 Batch (t): 0.364, 131.757/s, 131.757/s/gpu LR: 0.000005 Logit Scale: 73.722 Original_clip_loss: 0.16933 (0.12611) Loss: 0.16933 (0.12611)\n2025-04-02,10:46:41 | INFO | Train Epoch: 0 [ 72048/145000 (50%)] Data (t): 0.001 Batch (t): 0.364, 131.844/s, 131.844/s/gpu LR: 0.000005 Logit Scale: 73.727 Original_clip_loss: 0.14116 (0.12705) Loss: 0.14116 (0.12705)\n2025-04-02,10:47:17 | INFO | Train Epoch: 0 [ 76848/145000 (53%)] Data (t): 0.001 Batch (t): 0.364, 131.034/s, 131.034/s/gpu LR: 0.000005 Logit Scale: 73.742 Original_clip_loss: 0.14814 (0.12829) Loss: 0.14814 (0.12829)\n2025-04-02,10:47:53 | INFO | Train Epoch: 0 [ 81648/145000 (56%)] Data (t): 0.001 Batch (t): 0.365, 131.746/s, 131.746/s/gpu LR: 0.000005 Logit Scale: 73.750 Original_clip_loss: 0.20234 (0.13240) Loss: 0.20234 (0.13240)\n2025-04-02,10:48:30 | INFO | Train Epoch: 0 [ 86448/145000 (60%)] Data (t): 0.001 Batch (t): 0.364, 131.455/s, 131.455/s/gpu LR: 0.000005 Logit Scale: 73.760 Original_clip_loss: 0.086235 (0.12997) Loss: 0.086235 (0.12997)\n2025-04-02,10:49:06 | INFO | Train Epoch: 0 [ 91248/145000 (63%)] Data (t): 0.001 Batch (t): 0.364, 131.906/s, 131.906/s/gpu LR: 0.000005 Logit Scale: 73.773 Original_clip_loss: 0.12888 (0.12992) Loss: 0.12888 (0.12992)\n2025-04-02,10:49:43 | INFO | Train Epoch: 0 [ 96048/145000 (66%)] Data (t): 0.001 Batch (t): 0.364, 131.770/s, 131.770/s/gpu LR: 0.000005 Logit Scale: 73.783 Original_clip_loss: 0.12903 (0.12988) Loss: 0.12903 (0.12988)\n2025-04-02,10:50:19 | INFO | Train Epoch: 0 [100848/145000 (70%)] Data (t): 0.001 Batch (t): 0.364, 132.473/s, 132.473/s/gpu LR: 0.000005 Logit Scale: 73.788 Original_clip_loss: 0.19875 (0.13301) Loss: 0.19875 (0.13301)\n2025-04-02,10:50:56 | INFO | Train Epoch: 0 [105648/145000 (73%)] Data (t): 0.001 Batch (t): 0.364, 132.188/s, 132.188/s/gpu LR: 0.000005 Logit Scale: 73.795 Original_clip_loss: 0.12806 (0.13279) Loss: 0.12806 (0.13279)\n2025-04-02,10:51:32 | INFO | Train Epoch: 0 [110448/145000 (76%)] Data (t): 0.001 Batch (t): 0.364, 132.078/s, 132.078/s/gpu LR: 0.000005 Logit Scale: 73.800 Original_clip_loss: 0.076692 (0.13046) Loss: 0.076692 (0.13046)\n2025-04-02,10:52:08 | INFO | Train Epoch: 0 [115248/145000 (80%)] Data (t): 0.001 Batch (t): 0.364, 132.323/s, 132.323/s/gpu LR: 0.000005 Logit Scale: 73.806 Original_clip_loss: 0.082284 (0.12853) Loss: 0.082284 (0.12853)\n2025-04-02,10:52:45 | INFO | Train Epoch: 0 [120048/145000 (83%)] Data (t): 0.001 Batch (t): 0.364, 132.319/s, 132.319/s/gpu LR: 0.000005 Logit Scale: 73.818 Original_clip_loss: 0.058217 (0.12582) Loss: 0.058217 (0.12582)\n2025-04-02,10:53:21 | INFO | Train Epoch: 0 [124848/145000 (86%)] Data (t): 0.001 Batch (t): 0.363, 132.843/s, 132.843/s/gpu LR: 0.000005 Logit Scale: 73.823 Original_clip_loss: 0.10053 (0.12489) Loss: 0.10053 (0.12489)\n2025-04-02,10:53:57 | INFO | Train Epoch: 0 [129648/145000 (89%)] Data (t): 0.001 Batch (t): 0.363, 131.712/s, 131.712/s/gpu LR: 0.000005 Logit Scale: 73.830 Original_clip_loss: 0.078816 (0.12324) Loss: 0.078816 (0.12324)\n2025-04-02,10:54:34 | INFO | Train Epoch: 0 [134448/145000 (93%)] Data (t): 0.001 Batch (t): 0.364, 131.656/s, 131.656/s/gpu LR: 0.000005 Logit Scale: 73.844 Original_clip_loss: 0.13481 (0.12364) Loss: 0.13481 (0.12364)\n2025-04-02,10:55:10 | INFO | Train Epoch: 0 [139248/145000 (96%)] Data (t): 0.001 Batch (t): 0.364, 132.011/s, 132.011/s/gpu LR: 0.000005 Logit Scale: 73.849 Original_clip_loss: 0.061190 (0.12156) Loss: 0.061190 (0.12156)\n2025-04-02,10:55:47 | INFO | Train Epoch: 0 [144048/145000 (99%)] Data (t): 0.001 Batch (t): 0.364, 132.309/s, 132.309/s/gpu LR: 0.000005 Logit Scale: 73.858 Original_clip_loss: 0.094648 (0.12069) Loss: 0.094648 (0.12069)\n2025-04-02,10:55:54 | INFO | Train Epoch: 0 [144960/145000 (100%)] Data (t): 0.003 Batch (t): 0.364, 132.345/s, 132.345/s/gpu LR: 0.000005 Logit Scale: 73.859 Original_clip_loss: 0.15568 (0.12178) Loss: 0.15568 (0.12178)\n2025-04-02,10:55:55 | INFO | Start epoch 1\n2025-04-02,10:55:57 | INFO | Train Epoch: 1 [    48/145000 (0%)] Data (t): 1.109 Batch (t): 1.528, 31.4198/s, 31.4198/s/gpu LR: 0.000005 Logit Scale: 73.859 Original_clip_loss: 0.22464 (0.22464) Loss: 0.22464 (0.22464)\n2025-04-02,10:56:33 | INFO | Train Epoch: 1 [  4848/145000 (3%)] Data (t): 0.001 Batch (t): 0.364, 131.939/s, 131.939/s/gpu LR: 0.000005 Logit Scale: 73.863 Original_clip_loss: 0.22097 (0.22280) Loss: 0.22097 (0.22280)\n2025-04-02,10:57:10 | INFO | Train Epoch: 1 [  9648/145000 (7%)] Data (t): 0.001 Batch (t): 0.364, 132.071/s, 132.071/s/gpu LR: 0.000005 Logit Scale: 73.870 Original_clip_loss: 0.039332 (0.16165) Loss: 0.039332 (0.16165)\n2025-04-02,10:57:46 | INFO | Train Epoch: 1 [ 14448/145000 (10%)] Data (t): 0.001 Batch (t): 0.364, 132.174/s, 132.174/s/gpu LR: 0.000004 Logit Scale: 73.880 Original_clip_loss: 0.072458 (0.13935) Loss: 0.072458 (0.13935)\n2025-04-02,10:58:22 | INFO | Train Epoch: 1 [ 19248/145000 (13%)] Data (t): 0.001 Batch (t): 0.363, 131.663/s, 131.663/s/gpu LR: 0.000004 Logit Scale: 73.887 Original_clip_loss: 0.087076 (0.12890) Loss: 0.087076 (0.12890)\n2025-04-02,10:58:59 | INFO | Train Epoch: 1 [ 24048/145000 (17%)] Data (t): 0.001 Batch (t): 0.364, 131.387/s, 131.387/s/gpu LR: 0.000004 Logit Scale: 73.895 Original_clip_loss: 0.10750 (0.12533) Loss: 0.10750 (0.12533)\n2025-04-02,10:59:35 | INFO | Train Epoch: 1 [ 28848/145000 (20%)] Data (t): 0.001 Batch (t): 0.364, 131.880/s, 131.880/s/gpu LR: 0.000004 Logit Scale: 73.903 Original_clip_loss: 0.051421 (0.11477) Loss: 0.051421 (0.11477)\n2025-04-02,11:00:12 | INFO | Train Epoch: 1 [ 33648/145000 (23%)] Data (t): 0.001 Batch (t): 0.364, 132.708/s, 132.708/s/gpu LR: 0.000004 Logit Scale: 73.914 Original_clip_loss: 0.019266 (0.10283) Loss: 0.019266 (0.10283)\n2025-04-02,11:00:48 | INFO | Train Epoch: 1 [ 38448/145000 (27%)] Data (t): 0.001 Batch (t): 0.364, 131.021/s, 131.021/s/gpu LR: 0.000004 Logit Scale: 73.921 Original_clip_loss: 0.021916 (0.093842) Loss: 0.021916 (0.093842)\n2025-04-02,11:01:25 | INFO | Train Epoch: 1 [ 43248/145000 (30%)] Data (t): 0.001 Batch (t): 0.364, 130.223/s, 130.223/s/gpu LR: 0.000004 Logit Scale: 73.929 Original_clip_loss: 0.048853 (0.089343) Loss: 0.048853 (0.089343)\n2025-04-02,11:02:01 | INFO | Train Epoch: 1 [ 48048/145000 (33%)] Data (t): 0.001 Batch (t): 0.364, 130.955/s, 130.955/s/gpu LR: 0.000004 Logit Scale: 73.938 Original_clip_loss: 0.051392 (0.085893) Loss: 0.051392 (0.085893)\n2025-04-02,11:02:37 | INFO | Train Epoch: 1 [ 52848/145000 (36%)] Data (t): 0.001 Batch (t): 0.363, 132.082/s, 132.082/s/gpu LR: 0.000004 Logit Scale: 73.945 Original_clip_loss: 0.079901 (0.085394) Loss: 0.079901 (0.085394)\n2025-04-02,11:03:14 | INFO | Train Epoch: 1 [ 57648/145000 (40%)] Data (t): 0.001 Batch (t): 0.364, 131.837/s, 131.837/s/gpu LR: 0.000004 Logit Scale: 73.952 Original_clip_loss: 0.10653 (0.087019) Loss: 0.10653 (0.087019)\n2025-04-02,11:03:50 | INFO | Train Epoch: 1 [ 62448/145000 (43%)] Data (t): 0.001 Batch (t): 0.363, 132.661/s, 132.661/s/gpu LR: 0.000004 Logit Scale: 73.960 Original_clip_loss: 0.11894 (0.089299) Loss: 0.11894 (0.089299)\n2025-04-02,11:04:26 | INFO | Train Epoch: 1 [ 67248/145000 (46%)] Data (t): 0.001 Batch (t): 0.364, 132.028/s, 132.028/s/gpu LR: 0.000004 Logit Scale: 73.969 Original_clip_loss: 0.086955 (0.089143) Loss: 0.086955 (0.089143)\n2025-04-02,11:05:03 | INFO | Train Epoch: 1 [ 72048/145000 (50%)] Data (t): 0.001 Batch (t): 0.364, 131.949/s, 131.949/s/gpu LR: 0.000004 Logit Scale: 73.977 Original_clip_loss: 0.069365 (0.087907) Loss: 0.069365 (0.087907)\n2025-04-02,11:05:39 | INFO | Train Epoch: 1 [ 76848/145000 (53%)] Data (t): 0.001 Batch (t): 0.363, 132.425/s, 132.425/s/gpu LR: 0.000004 Logit Scale: 73.985 Original_clip_loss: 0.012509 (0.083472) Loss: 0.012509 (0.083472)\n2025-04-02,11:06:16 | INFO | Train Epoch: 1 [ 81648/145000 (56%)] Data (t): 0.001 Batch (t): 0.364, 131.836/s, 131.836/s/gpu LR: 0.000004 Logit Scale: 73.997 Original_clip_loss: 0.021157 (0.080010) Loss: 0.021157 (0.080010)\n2025-04-02,11:06:52 | INFO | Train Epoch: 1 [ 86448/145000 (60%)] Data (t): 0.001 Batch (t): 0.364, 131.783/s, 131.783/s/gpu LR: 0.000004 Logit Scale: 74.007 Original_clip_loss: 0.13546 (0.082928) Loss: 0.13546 (0.082928)\n2025-04-02,11:07:28 | INFO | Train Epoch: 1 [ 91248/145000 (63%)] Data (t): 0.001 Batch (t): 0.364, 132.251/s, 132.251/s/gpu LR: 0.000004 Logit Scale: 74.010 Original_clip_loss: 0.057947 (0.081679) Loss: 0.057947 (0.081679)\n2025-04-02,11:08:05 | INFO | Train Epoch: 1 [ 96048/145000 (66%)] Data (t): 0.001 Batch (t): 0.363, 131.817/s, 131.817/s/gpu LR: 0.000004 Logit Scale: 74.018 Original_clip_loss: 0.062192 (0.080751) Loss: 0.062192 (0.080751)\n2025-04-02,11:08:41 | INFO | Train Epoch: 1 [100848/145000 (70%)] Data (t): 0.001 Batch (t): 0.364, 132.133/s, 132.133/s/gpu LR: 0.000003 Logit Scale: 74.028 Original_clip_loss: 0.053978 (0.079534) Loss: 0.053978 (0.079534)\n2025-04-02,11:09:18 | INFO | Train Epoch: 1 [105648/145000 (73%)] Data (t): 0.001 Batch (t): 0.364, 131.719/s, 131.719/s/gpu LR: 0.000003 Logit Scale: 74.034 Original_clip_loss: 0.041069 (0.077862) Loss: 0.041069 (0.077862)\n2025-04-02,11:09:54 | INFO | Train Epoch: 1 [110448/145000 (76%)] Data (t): 0.001 Batch (t): 0.364, 131.472/s, 131.472/s/gpu LR: 0.000003 Logit Scale: 74.042 Original_clip_loss: 0.29447 (0.086887) Loss: 0.29447 (0.086887)\n2025-04-02,11:10:30 | INFO | Train Epoch: 1 [115248/145000 (80%)] Data (t): 0.001 Batch (t): 0.364, 132.029/s, 132.029/s/gpu LR: 0.000003 Logit Scale: 74.047 Original_clip_loss: 0.080113 (0.086616) Loss: 0.080113 (0.086616)\n2025-04-02,11:11:07 | INFO | Train Epoch: 1 [120048/145000 (83%)] Data (t): 0.001 Batch (t): 0.364, 132.159/s, 132.159/s/gpu LR: 0.000003 Logit Scale: 74.053 Original_clip_loss: 0.039499 (0.084804) Loss: 0.039499 (0.084804)\n2025-04-02,11:11:43 | INFO | Train Epoch: 1 [124848/145000 (86%)] Data (t): 0.001 Batch (t): 0.364, 130.443/s, 130.443/s/gpu LR: 0.000003 Logit Scale: 74.060 Original_clip_loss: 0.041841 (0.083213) Loss: 0.041841 (0.083213)\n2025-04-02,11:12:19 | INFO | Train Epoch: 1 [129648/145000 (89%)] Data (t): 0.001 Batch (t): 0.363, 132.386/s, 132.386/s/gpu LR: 0.000003 Logit Scale: 74.064 Original_clip_loss: 0.057266 (0.082286) Loss: 0.057266 (0.082286)\n2025-04-02,11:12:56 | INFO | Train Epoch: 1 [134448/145000 (93%)] Data (t): 0.001 Batch (t): 0.363, 132.016/s, 132.016/s/gpu LR: 0.000003 Logit Scale: 74.073 Original_clip_loss: 0.035657 (0.080678) Loss: 0.035657 (0.080678)\n2025-04-02,11:13:32 | INFO | Train Epoch: 1 [139248/145000 (96%)] Data (t): 0.001 Batch (t): 0.364, 130.480/s, 130.480/s/gpu LR: 0.000003 Logit Scale: 74.078 Original_clip_loss: 0.027104 (0.078893) Loss: 0.027104 (0.078893)\n2025-04-02,11:14:08 | INFO | Train Epoch: 1 [144048/145000 (99%)] Data (t): 0.001 Batch (t): 0.364, 131.983/s, 131.983/s/gpu LR: 0.000003 Logit Scale: 74.086 Original_clip_loss: 0.085460 (0.079104) Loss: 0.085460 (0.079104)\n2025-04-02,11:14:15 | INFO | Train Epoch: 1 [144960/145000 (100%)] Data (t): 0.003 Batch (t): 0.364, 131.597/s, 131.597/s/gpu LR: 0.000003 Logit Scale: 74.087 Original_clip_loss: 0.011923 (0.077005) Loss: 0.011923 (0.077005)\n2025-04-02,11:14:17 | INFO | Start epoch 2\n2025-04-02,11:14:18 | INFO | Train Epoch: 2 [    48/145000 (0%)] Data (t): 0.910 Batch (t): 1.294, 37.0814/s, 37.0814/s/gpu LR: 0.000003 Logit Scale: 74.087 Original_clip_loss: 0.078321 (0.078321) Loss: 0.078321 (0.078321)\n2025-04-02,11:14:55 | INFO | Train Epoch: 2 [  4848/145000 (3%)] Data (t): 0.001 Batch (t): 0.365, 131.496/s, 131.496/s/gpu LR: 0.000003 Logit Scale: 74.093 Original_clip_loss: 0.063491 (0.070906) Loss: 0.063491 (0.070906)\n2025-04-02,11:15:31 | INFO | Train Epoch: 2 [  9648/145000 (7%)] Data (t): 0.001 Batch (t): 0.364, 131.881/s, 131.881/s/gpu LR: 0.000003 Logit Scale: 74.100 Original_clip_loss: 0.072217 (0.071343) Loss: 0.072217 (0.071343)\n2025-04-02,11:16:08 | INFO | Train Epoch: 2 [ 14448/145000 (10%)] Data (t): 0.001 Batch (t): 0.364, 131.988/s, 131.988/s/gpu LR: 0.000003 Logit Scale: 74.107 Original_clip_loss: 0.082289 (0.074079) Loss: 0.082289 (0.074079)\n2025-04-02,11:16:44 | INFO | Train Epoch: 2 [ 19248/145000 (13%)] Data (t): 0.001 Batch (t): 0.364, 132.514/s, 132.514/s/gpu LR: 0.000003 Logit Scale: 74.114 Original_clip_loss: 0.021065 (0.063476) Loss: 0.021065 (0.063476)\n2025-04-02,11:17:21 | INFO | Train Epoch: 2 [ 24048/145000 (17%)] Data (t): 0.001 Batch (t): 0.364, 131.902/s, 131.902/s/gpu LR: 0.000003 Logit Scale: 74.121 Original_clip_loss: 0.15716 (0.079090) Loss: 0.15716 (0.079090)\n2025-04-02,11:17:57 | INFO | Train Epoch: 2 [ 28848/145000 (20%)] Data (t): 0.001 Batch (t): 0.364, 131.657/s, 131.657/s/gpu LR: 0.000002 Logit Scale: 74.126 Original_clip_loss: 0.077781 (0.078903) Loss: 0.077781 (0.078903)\n2025-04-02,11:18:33 | INFO | Train Epoch: 2 [ 33648/145000 (23%)] Data (t): 0.001 Batch (t): 0.364, 132.088/s, 132.088/s/gpu LR: 0.000002 Logit Scale: 74.136 Original_clip_loss: 0.023503 (0.071978) Loss: 0.023503 (0.071978)\n2025-04-02,11:19:10 | INFO | Train Epoch: 2 [ 38448/145000 (27%)] Data (t): 0.001 Batch (t): 0.364, 132.435/s, 132.435/s/gpu LR: 0.000002 Logit Scale: 74.144 Original_clip_loss: 0.022215 (0.066449) Loss: 0.022215 (0.066449)\n2025-04-02,11:19:46 | INFO | Train Epoch: 2 [ 43248/145000 (30%)] Data (t): 0.001 Batch (t): 0.364, 132.467/s, 132.467/s/gpu LR: 0.000002 Logit Scale: 74.150 Original_clip_loss: 0.047324 (0.064536) Loss: 0.047324 (0.064536)\n2025-04-02,11:20:23 | INFO | Train Epoch: 2 [ 48048/145000 (33%)] Data (t): 0.001 Batch (t): 0.364, 132.541/s, 132.541/s/gpu LR: 0.000002 Logit Scale: 74.158 Original_clip_loss: 0.046418 (0.062889) Loss: 0.046418 (0.062889)\n2025-04-02,11:20:59 | INFO | Train Epoch: 2 [ 52848/145000 (36%)] Data (t): 0.001 Batch (t): 0.364, 131.477/s, 131.477/s/gpu LR: 0.000002 Logit Scale: 74.165 Original_clip_loss: 0.017015 (0.059066) Loss: 0.017015 (0.059066)\n2025-04-02,11:21:36 | INFO | Train Epoch: 2 [ 57648/145000 (40%)] Data (t): 0.001 Batch (t): 0.364, 130.827/s, 130.827/s/gpu LR: 0.000002 Logit Scale: 74.172 Original_clip_loss: 0.037017 (0.057370) Loss: 0.037017 (0.057370)\n2025-04-02,11:22:12 | INFO | Train Epoch: 2 [ 62448/145000 (43%)] Data (t): 0.001 Batch (t): 0.364, 131.719/s, 131.719/s/gpu LR: 0.000002 Logit Scale: 74.177 Original_clip_loss: 0.026949 (0.055197) Loss: 0.026949 (0.055197)\n2025-04-02,11:22:48 | INFO | Train Epoch: 2 [ 67248/145000 (46%)] Data (t): 0.001 Batch (t): 0.364, 131.953/s, 131.953/s/gpu LR: 0.000002 Logit Scale: 74.181 Original_clip_loss: 0.070566 (0.056222) Loss: 0.070566 (0.056222)\n2025-04-02,11:23:25 | INFO | Train Epoch: 2 [ 72048/145000 (50%)] Data (t): 0.001 Batch (t): 0.364, 131.254/s, 131.254/s/gpu LR: 0.000002 Logit Scale: 74.186 Original_clip_loss: 0.051150 (0.055905) Loss: 0.051150 (0.055905)\n2025-04-02,11:24:01 | INFO | Train Epoch: 2 [ 76848/145000 (53%)] Data (t): 0.001 Batch (t): 0.364, 132.032/s, 132.032/s/gpu LR: 0.000002 Logit Scale: 74.191 Original_clip_loss: 0.025192 (0.054098) Loss: 0.025192 (0.054098)\n2025-04-02,11:24:38 | INFO | Train Epoch: 2 [ 81648/145000 (56%)] Data (t): 0.001 Batch (t): 0.364, 131.632/s, 131.632/s/gpu LR: 0.000002 Logit Scale: 74.196 Original_clip_loss: 0.046126 (0.053655) Loss: 0.046126 (0.053655)\n2025-04-02,11:25:14 | INFO | Train Epoch: 2 [ 86448/145000 (60%)] Data (t): 0.001 Batch (t): 0.364, 130.956/s, 130.956/s/gpu LR: 0.000002 Logit Scale: 74.202 Original_clip_loss: 0.042838 (0.053086) Loss: 0.042838 (0.053086)\n2025-04-02,11:25:50 | INFO | Train Epoch: 2 [ 91248/145000 (63%)] Data (t): 0.001 Batch (t): 0.364, 131.875/s, 131.875/s/gpu LR: 0.000002 Logit Scale: 74.206 Original_clip_loss: 0.083091 (0.054586) Loss: 0.083091 (0.054586)\n2025-04-02,11:26:27 | INFO | Train Epoch: 2 [ 96048/145000 (66%)] Data (t): 0.001 Batch (t): 0.363, 132.202/s, 132.202/s/gpu LR: 0.000001 Logit Scale: 74.210 Original_clip_loss: 0.023794 (0.053120) Loss: 0.023794 (0.053120)\n2025-04-02,11:27:03 | INFO | Train Epoch: 2 [100848/145000 (70%)] Data (t): 0.001 Batch (t): 0.363, 132.783/s, 132.783/s/gpu LR: 0.000001 Logit Scale: 74.214 Original_clip_loss: 0.036614 (0.052370) Loss: 0.036614 (0.052370)\n2025-04-02,11:27:39 | INFO | Train Epoch: 2 [105648/145000 (73%)] Data (t): 0.001 Batch (t): 0.364, 131.512/s, 131.512/s/gpu LR: 0.000001 Logit Scale: 74.219 Original_clip_loss: 0.032147 (0.051491) Loss: 0.032147 (0.051491)\n2025-04-02,11:28:16 | INFO | Train Epoch: 2 [110448/145000 (76%)] Data (t): 0.001 Batch (t): 0.364, 131.868/s, 131.868/s/gpu LR: 0.000001 Logit Scale: 74.222 Original_clip_loss: 0.024162 (0.050352) Loss: 0.024162 (0.050352)\n2025-04-02,11:28:52 | INFO | Train Epoch: 2 [115248/145000 (80%)] Data (t): 0.001 Batch (t): 0.363, 132.472/s, 132.472/s/gpu LR: 0.000001 Logit Scale: 74.224 Original_clip_loss: 0.034678 (0.049725) Loss: 0.034678 (0.049725)\n2025-04-02,11:29:28 | INFO | Train Epoch: 2 [120048/145000 (83%)] Data (t): 0.001 Batch (t): 0.363, 132.562/s, 132.562/s/gpu LR: 0.000001 Logit Scale: 74.228 Original_clip_loss: 0.060358 (0.050134) Loss: 0.060358 (0.050134)\n2025-04-02,11:30:05 | INFO | Train Epoch: 2 [124848/145000 (86%)] Data (t): 0.001 Batch (t): 0.364, 130.732/s, 130.732/s/gpu LR: 0.000001 Logit Scale: 74.231 Original_clip_loss: 0.12560 (0.052929) Loss: 0.12560 (0.052929)\n2025-04-02,11:30:41 | INFO | Train Epoch: 2 [129648/145000 (89%)] Data (t): 0.001 Batch (t): 0.364, 132.223/s, 132.223/s/gpu LR: 0.000001 Logit Scale: 74.234 Original_clip_loss: 0.15439 (0.056553) Loss: 0.15439 (0.056553)\n2025-04-02,11:31:18 | INFO | Train Epoch: 2 [134448/145000 (93%)] Data (t): 0.001 Batch (t): 0.363, 132.167/s, 132.167/s/gpu LR: 0.000001 Logit Scale: 74.237 Original_clip_loss: 0.28832 (0.064545) Loss: 0.28832 (0.064545)\n2025-04-02,11:31:54 | INFO | Train Epoch: 2 [139248/145000 (96%)] Data (t): 0.001 Batch (t): 0.363, 132.239/s, 132.239/s/gpu LR: 0.000001 Logit Scale: 74.239 Original_clip_loss: 0.048289 (0.064003) Loss: 0.048289 (0.064003)\n2025-04-02,11:32:30 | INFO | Train Epoch: 2 [144048/145000 (99%)] Data (t): 0.001 Batch (t): 0.364, 131.716/s, 131.716/s/gpu LR: 0.000001 Logit Scale: 74.240 Original_clip_loss: 0.059929 (0.063871) Loss: 0.059929 (0.063871)\n2025-04-02,11:32:37 | INFO | Train Epoch: 2 [144960/145000 (100%)] Data (t): 0.003 Batch (t): 0.362, 132.497/s, 132.497/s/gpu LR: 0.000001 Logit Scale: 74.241 Original_clip_loss: 0.018106 (0.062441) Loss: 0.018106 (0.062441)\n2025-04-02,11:32:39 | INFO | Start epoch 3\n2025-04-02,11:32:40 | INFO | Train Epoch: 3 [    48/145000 (0%)] Data (t): 0.892 Batch (t): 1.298, 36.9891/s, 36.9891/s/gpu LR: 0.000001 Logit Scale: 74.241 Original_clip_loss: 0.039524 (0.039524) Loss: 0.039524 (0.039524)\n2025-04-02,11:33:17 | INFO | Train Epoch: 3 [  4848/145000 (3%)] Data (t): 0.001 Batch (t): 0.364, 132.006/s, 132.006/s/gpu LR: 0.000001 Logit Scale: 74.244 Original_clip_loss: 0.094108 (0.066816) Loss: 0.094108 (0.066816)\n2025-04-02,11:33:53 | INFO | Train Epoch: 3 [  9648/145000 (7%)] Data (t): 0.001 Batch (t): 0.364, 132.764/s, 132.764/s/gpu LR: 0.000001 Logit Scale: 74.247 Original_clip_loss: 0.033162 (0.055598) Loss: 0.033162 (0.055598)\n2025-04-02,11:34:29 | INFO | Train Epoch: 3 [ 14448/145000 (10%)] Data (t): 0.001 Batch (t): 0.363, 132.175/s, 132.175/s/gpu LR: 0.000001 Logit Scale: 74.250 Original_clip_loss: 0.068785 (0.058895) Loss: 0.068785 (0.058895)\n2025-04-02,11:35:06 | INFO | Train Epoch: 3 [ 19248/145000 (13%)] Data (t): 0.001 Batch (t): 0.364, 132.063/s, 132.063/s/gpu LR: 0.000001 Logit Scale: 74.253 Original_clip_loss: 0.042015 (0.055519) Loss: 0.042015 (0.055519)\n2025-04-02,11:35:42 | INFO | Train Epoch: 3 [ 24048/145000 (17%)] Data (t): 0.001 Batch (t): 0.364, 132.591/s, 132.591/s/gpu LR: 0.000001 Logit Scale: 74.256 Original_clip_loss: 0.069862 (0.057909) Loss: 0.069862 (0.057909)\n2025-04-02,11:36:18 | INFO | Train Epoch: 3 [ 28848/145000 (20%)] Data (t): 0.001 Batch (t): 0.364, 131.805/s, 131.805/s/gpu LR: 0.000001 Logit Scale: 74.258 Original_clip_loss: 0.013521 (0.051568) Loss: 0.013521 (0.051568)\n2025-04-02,11:36:55 | INFO | Train Epoch: 3 [ 33648/145000 (23%)] Data (t): 0.001 Batch (t): 0.364, 132.531/s, 132.531/s/gpu LR: 0.000001 Logit Scale: 74.260 Original_clip_loss: 0.036011 (0.049624) Loss: 0.036011 (0.049624)\n2025-04-02,11:37:31 | INFO | Train Epoch: 3 [ 38448/145000 (27%)] Data (t): 0.001 Batch (t): 0.364, 131.649/s, 131.649/s/gpu LR: 0.000000 Logit Scale: 74.262 Original_clip_loss: 0.020875 (0.046429) Loss: 0.020875 (0.046429)\n2025-04-02,11:38:09 | INFO | Train Epoch: 3 [ 43248/145000 (30%)] Data (t): 0.010 Batch (t): 0.373, 132.257/s, 132.257/s/gpu LR: 0.000000 Logit Scale: 74.263 Original_clip_loss: 0.016963 (0.043483) Loss: 0.016963 (0.043483)\n2025-04-02,11:38:45 | INFO | Train Epoch: 3 [ 48048/145000 (33%)] Data (t): 0.001 Batch (t): 0.364, 132.529/s, 132.529/s/gpu LR: 0.000000 Logit Scale: 74.263 Original_clip_loss: 0.042506 (0.043394) Loss: 0.042506 (0.043394)\n2025-04-02,11:39:21 | INFO | Train Epoch: 3 [ 52848/145000 (36%)] Data (t): 0.001 Batch (t): 0.364, 130.382/s, 130.382/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.045075 (0.043534) Loss: 0.045075 (0.043534)\n2025-04-02,11:39:58 | INFO | Train Epoch: 3 [ 57648/145000 (40%)] Data (t): 0.001 Batch (t): 0.364, 131.347/s, 131.347/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.010928 (0.041026) Loss: 0.010928 (0.041026)\n2025-04-02,11:40:34 | INFO | Train Epoch: 3 [ 62448/145000 (43%)] Data (t): 0.001 Batch (t): 0.364, 131.936/s, 131.936/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.014512 (0.039132) Loss: 0.014512 (0.039132)\n2025-04-02,11:41:11 | INFO | Train Epoch: 3 [ 67248/145000 (46%)] Data (t): 0.001 Batch (t): 0.364, 131.780/s, 131.780/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.096001 (0.042923) Loss: 0.096001 (0.042923)\n2025-04-02,11:41:47 | INFO | Train Epoch: 3 [ 72048/145000 (50%)] Data (t): 0.001 Batch (t): 0.363, 132.395/s, 132.395/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.039757 (0.042725) Loss: 0.039757 (0.042725)\n2025-04-02,11:42:23 | INFO | Train Epoch: 3 [ 76848/145000 (53%)] Data (t): 0.001 Batch (t): 0.364, 132.368/s, 132.368/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.014058 (0.041039) Loss: 0.014058 (0.041039)\n2025-04-02,11:43:00 | INFO | Train Epoch: 3 [ 81648/145000 (56%)] Data (t): 0.001 Batch (t): 0.364, 130.325/s, 130.325/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.043844 (0.041195) Loss: 0.043844 (0.041195)\n2025-04-02,11:43:36 | INFO | Train Epoch: 3 [ 86448/145000 (60%)] Data (t): 0.001 Batch (t): 0.364, 131.776/s, 131.776/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.047545 (0.041529) Loss: 0.047545 (0.041529)\n2025-04-02,11:44:13 | INFO | Train Epoch: 3 [ 91248/145000 (63%)] Data (t): 0.001 Batch (t): 0.364, 132.504/s, 132.504/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.044156 (0.041660) Loss: 0.044156 (0.041660)\n2025-04-02,11:44:49 | INFO | Train Epoch: 3 [ 96048/145000 (66%)] Data (t): 0.001 Batch (t): 0.364, 132.426/s, 132.426/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.079367 (0.043456) Loss: 0.079367 (0.043456)\n2025-04-02,11:45:25 | INFO | Train Epoch: 3 [100848/145000 (70%)] Data (t): 0.001 Batch (t): 0.364, 131.465/s, 131.465/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.044213 (0.043490) Loss: 0.044213 (0.043490)\n2025-04-02,11:46:02 | INFO | Train Epoch: 3 [105648/145000 (73%)] Data (t): 0.001 Batch (t): 0.364, 132.276/s, 132.276/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.037568 (0.043233) Loss: 0.037568 (0.043233)\n2025-04-02,11:46:38 | INFO | Train Epoch: 3 [110448/145000 (76%)] Data (t): 0.001 Batch (t): 0.364, 132.050/s, 132.050/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.013791 (0.042006) Loss: 0.013791 (0.042006)\n2025-04-02,11:47:15 | INFO | Train Epoch: 3 [115248/145000 (80%)] Data (t): 0.001 Batch (t): 0.364, 131.691/s, 131.691/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.064729 (0.042915) Loss: 0.064729 (0.042915)\n2025-04-02,11:47:51 | INFO | Train Epoch: 3 [120048/145000 (83%)] Data (t): 0.001 Batch (t): 0.364, 130.689/s, 130.689/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.044445 (0.042974) Loss: 0.044445 (0.042974)\n2025-04-02,11:48:27 | INFO | Train Epoch: 3 [124848/145000 (86%)] Data (t): 0.001 Batch (t): 0.364, 131.607/s, 131.607/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.089825 (0.044709) Loss: 0.089825 (0.044709)\n2025-04-02,11:49:04 | INFO | Train Epoch: 3 [129648/145000 (89%)] Data (t): 0.001 Batch (t): 0.364, 132.323/s, 132.323/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.060633 (0.045278) Loss: 0.060633 (0.045278)\n2025-04-02,11:49:40 | INFO | Train Epoch: 3 [134448/145000 (93%)] Data (t): 0.001 Batch (t): 0.364, 132.367/s, 132.367/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.025241 (0.044587) Loss: 0.025241 (0.044587)\n2025-04-02,11:50:17 | INFO | Train Epoch: 3 [139248/145000 (96%)] Data (t): 0.001 Batch (t): 0.364, 132.053/s, 132.053/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.0029974 (0.043200) Loss: 0.0029974 (0.043200)\n2025-04-02,11:50:53 | INFO | Train Epoch: 3 [144048/145000 (99%)] Data (t): 0.001 Batch (t): 0.364, 131.482/s, 131.482/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.10345 (0.045144) Loss: 0.10345 (0.045144)\n2025-04-02,11:51:00 | INFO | Train Epoch: 3 [144960/145000 (100%)] Data (t): 0.003 Batch (t): 0.363, 131.946/s, 131.946/s/gpu LR: 0.000000 Logit Scale: 74.264 Original_clip_loss: 0.0064845 (0.043936) Loss: 0.0064845 (0.043936)\nI0402 11:51:02.145000 216 torch/_dynamo/utils.py:399] TorchDynamo compilation metrics:\nI0402 11:51:02.145000 216 torch/_dynamo/utils.py:399] Function    Runtimes (s)\nI0402 11:51:02.145000 216 torch/_dynamo/utils.py:399] ----------  --------------\nI0402 11:51:02.151000 216 torch/_subclasses/fake_tensor.py:2423] FakeTensor cache stats:\nI0402 11:51:02.152000 216 torch/_subclasses/fake_tensor.py:2424]   cache_hits: 0\nI0402 11:51:02.152000 216 torch/_subclasses/fake_tensor.py:2425]   cache_misses: 0\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"import torch\nimport open_clip\n\n# Path to your trained checkpoint\ncheckpoint_path = \"checkpoints/og_fine_tuned_Clip_10_epochs/checkpoints/epoch_4.pt\"\n\n# 1. Create the model architecture from scratch (without loading pretrained weights)\nmodel_og_fine_tuned_Clip_10_epochs, preprocess_ft, preprocess_val = open_clip.create_model_and_transforms(\n    \"RN50\", pretrained=None\n)\n\n# 2. Load the trained checkpoint manually\ncheckpoint = torch.load(checkpoint_path, map_location=\"cpu\",weights_only=True)\n\n# If the state_dict is nested under a key (like \"state_dict\"), adjust accordingly\nif \"state_dict\" in checkpoint:\n    checkpoint = checkpoint[\"state_dict\"]\n\n# Load checkpoint weights into model\nmodel_og_fine_tuned_Clip_10_epochs.load_state_dict(checkpoint, strict=False)  # Use strict=False to avoid missing keys error\n\n# 3. Move model to GPU (if available)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel_og_fine_tuned_Clip_10_epochs = model_og_fine_tuned_Clip_10_epochs.to(device)\nmodel_og_fine_tuned_Clip_10_epochs.eval()\nprint(\"Model loaded successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:51:04.451885Z","iopub.execute_input":"2025-04-02T11:51:04.452210Z","iopub.status.idle":"2025-04-02T11:51:06.976376Z","shell.execute_reply.started":"2025-04-02T11:51:04.452180Z","shell.execute_reply":"2025-04-02T11:51:06.975454Z"}},"outputs":[{"name":"stdout","text":"Model loaded successfully!\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"#!rm -rf checkpoints/og_fine_tuned_Clip_10_epochs\n#!ls checkpoints/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:51:06.978386Z","iopub.execute_input":"2025-04-02T11:51:06.978620Z","iopub.status.idle":"2025-04-02T11:51:06.982117Z","shell.execute_reply.started":"2025-04-02T11:51:06.978601Z","shell.execute_reply":"2025-04-02T11:51:06.981168Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"# import shutil\n\n# shutil.make_archive(\"/kaggle/working/cyclip_checkpoints\", 'zip', \"/kaggle/working/checkpoints\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:51:06.983480Z","iopub.execute_input":"2025-04-02T11:51:06.983784Z","iopub.status.idle":"2025-04-02T11:51:06.999659Z","shell.execute_reply.started":"2025-04-02T11:51:06.983756Z","shell.execute_reply":"2025-04-02T11:51:06.998851Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"#      EVALUATING BELOW","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:51:07.000457Z","iopub.execute_input":"2025-04-02T11:51:07.000698Z","iopub.status.idle":"2025-04-02T11:51:07.017483Z","shell.execute_reply.started":"2025-04-02T11:51:07.000678Z","shell.execute_reply":"2025-04-02T11:51:07.016578Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"test_data = [item for item in karpathy_data[\"images\"] if item[\"split\"] == \"test\"]\nall_captions = []\nall_images = []\nfor item in test_data:\n    for sentence in item[\"sentences\"]:\n        all_captions.append(sentence[\"raw\"])\n        all_images.append(item[\"filename\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:51:07.018212Z","iopub.execute_input":"2025-04-02T11:51:07.018462Z","iopub.status.idle":"2025-04-02T11:51:07.106229Z","shell.execute_reply.started":"2025-04-02T11:51:07.018442Z","shell.execute_reply":"2025-04-02T11:51:07.105313Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"#FOR FINE TUNED CLIP","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:51:07.107054Z","iopub.execute_input":"2025-04-02T11:51:07.107287Z","iopub.status.idle":"2025-04-02T11:51:07.110534Z","shell.execute_reply.started":"2025-04-02T11:51:07.107268Z","shell.execute_reply":"2025-04-02T11:51:07.109734Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"# Compute embeddings\n\nimage_root = \"/kaggle/input/flickr30k/Images\"\ntext_embeds, image_embeds = get_all_embeddings(\n    model_dino_fine_tuned_Clip_10_epochs, all_captions, all_images, root=image_root,\n    preprocess=preprocess, tokenizer=tokenizer, device=device , batch_size=48\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:51:07.112394Z","iopub.execute_input":"2025-04-02T11:51:07.112630Z","iopub.status.idle":"2025-04-02T11:52:22.365114Z","shell.execute_reply.started":"2025-04-02T11:51:07.112610Z","shell.execute_reply":"2025-04-02T11:52:22.364349Z"}},"outputs":[{"name":"stderr","text":"Encoding batches: 100%|██████████| 105/105 [01:15<00:00,  1.40it/s]\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"# Evaluate\nresults = itm_eval(text_embeds, image_embeds)\nprint(\"📊 Evaluation Results:\")\nfor k, v in results.items():\n    print(f\"{k}: {v:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:52:22.366217Z","iopub.execute_input":"2025-04-02T11:52:22.366485Z","iopub.status.idle":"2025-04-02T11:52:23.593316Z","shell.execute_reply.started":"2025-04-02T11:52:22.366463Z","shell.execute_reply":"2025-04-02T11:52:23.592543Z"}},"outputs":[{"name":"stdout","text":"📊 Evaluation Results:\ntxt_r1: 91.66\ntxt_r5: 96.74\ntxt_r10: 98.08\ntxt_r_mean: 95.49\nimg_r1: 43.06\nimg_r5: 73.62\nimg_r10: 82.62\nimg_r_mean: 66.43\nr_mean: 80.96\n","output_type":"stream"}],"execution_count":88},{"cell_type":"code","source":"image_root = \"/kaggle/input/flickr30k/Images\"\ntext_embeds, image_embeds = get_all_embeddings(\n    model_og_fine_tuned_Clip_10_epochs, all_captions, all_images, root=image_root,\n    preprocess=preprocess, tokenizer=tokenizer, device=device , batch_size=48\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:52:23.594112Z","iopub.execute_input":"2025-04-02T11:52:23.594416Z","iopub.status.idle":"2025-04-02T11:53:27.870761Z","shell.execute_reply.started":"2025-04-02T11:52:23.594384Z","shell.execute_reply":"2025-04-02T11:53:27.869781Z"}},"outputs":[{"name":"stderr","text":"Encoding batches: 100%|██████████| 105/105 [01:04<00:00,  1.63it/s]\n","output_type":"stream"}],"execution_count":89},{"cell_type":"code","source":"# Evaluate\nresults = itm_eval(text_embeds, image_embeds)\nprint(\"📊 Evaluation Results:\")\nfor k, v in results.items():\n    print(f\"{k}: {v:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:53:27.871617Z","iopub.execute_input":"2025-04-02T11:53:27.871882Z","iopub.status.idle":"2025-04-02T11:53:29.066796Z","shell.execute_reply.started":"2025-04-02T11:53:27.871860Z","shell.execute_reply":"2025-04-02T11:53:29.066011Z"}},"outputs":[{"name":"stdout","text":"📊 Evaluation Results:\ntxt_r1: 91.38\ntxt_r5: 96.54\ntxt_r10: 98.06\ntxt_r_mean: 95.33\nimg_r1: 42.30\nimg_r5: 73.08\nimg_r10: 82.38\nimg_r_mean: 65.92\nr_mean: 80.62\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"# CONSISTENCY METRICS BELOW","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:57:20.139311Z","iopub.execute_input":"2025-04-02T11:57:20.139605Z","iopub.status.idle":"2025-04-02T11:57:20.143160Z","shell.execute_reply.started":"2025-04-02T11:57:20.139582Z","shell.execute_reply":"2025-04-02T11:57:20.142238Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"test_records = []\nfor item in test_data:\n    img_filename = f\"/kaggle/input/flickr30k/Images/{item['filename']}\"\n    for sentence in item[\"sentences\"]:\n        caption = sentence[\"raw\"]\n        test_records.append({\"image\": img_filename, \"caption\": caption})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:57:20.146431Z","iopub.execute_input":"2025-04-02T11:57:20.146652Z","iopub.status.idle":"2025-04-02T11:57:20.165311Z","shell.execute_reply.started":"2025-04-02T11:57:20.146632Z","shell.execute_reply":"2025-04-02T11:57:20.164597Z"}},"outputs":[],"execution_count":103},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass CyCLIPDataset(Dataset):\n    def __init__(self, records, image_transform):\n        self.records = records\n        self.image_transform = image_transform\n\n    def __len__(self):\n        return len(self.records)\n\n    def __getitem__(self, idx):\n        record = self.records[idx]\n        image = self.image_transform(Image.open(record[\"image\"]).convert(\"RGB\"))\n        text = tokenizer(record[\"caption\"]).squeeze(0)  # remove batch dim\n        return image, text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:57:20.178007Z","iopub.execute_input":"2025-04-02T11:57:20.178265Z","iopub.status.idle":"2025-04-02T11:57:20.183113Z","shell.execute_reply.started":"2025-04-02T11:57:20.178241Z","shell.execute_reply":"2025-04-02T11:57:20.182347Z"}},"outputs":[],"execution_count":104},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntest_dataset = CyCLIPDataset(test_records, preprocess)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:57:20.185993Z","iopub.execute_input":"2025-04-02T11:57:20.186202Z","iopub.status.idle":"2025-04-02T11:57:20.203809Z","shell.execute_reply.started":"2025-04-02T11:57:20.186181Z","shell.execute_reply":"2025-04-02T11:57:20.202999Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"# compute_consistency_score calculate mean of similarities\n\n# CLIP final with og Fine tuning\n\nscore = compute_consistency_score(model_dino_fine_tuned_Clip_10_epochs, test_loader, device)\n\nprint(f\"Consistency Score: {score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:57:20.211797Z","iopub.execute_input":"2025-04-02T11:57:20.212128Z","iopub.status.idle":"2025-04-02T11:58:25.435934Z","shell.execute_reply.started":"2025-04-02T11:57:20.212104Z","shell.execute_reply":"2025-04-02T11:58:25.435153Z"}},"outputs":[{"name":"stdout","text":"Consistency Score: 0.4832\n","output_type":"stream"}],"execution_count":106},{"cell_type":"code","source":"# CLIP final with og Fine tuning\n\nscore = compute_consistency_score(model_og_fine_tuned_Clip_10_epochs, test_loader, device)\n\nprint(f\"Consistency Score: {score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T11:58:25.436852Z","iopub.execute_input":"2025-04-02T11:58:25.437173Z","iopub.status.idle":"2025-04-02T11:59:30.971477Z","shell.execute_reply.started":"2025-04-02T11:58:25.437145Z","shell.execute_reply":"2025-04-02T11:59:30.970547Z"}},"outputs":[{"name":"stdout","text":"Consistency Score: 0.4725\n","output_type":"stream"}],"execution_count":107}]}