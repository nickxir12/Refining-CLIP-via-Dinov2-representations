{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1111749,"sourceType":"datasetVersion","datasetId":623329},{"sourceId":1706129,"sourceType":"datasetVersion","datasetId":1011404},{"sourceId":11198457,"sourceType":"datasetVersion","datasetId":6991709},{"sourceId":11206158,"sourceType":"datasetVersion","datasetId":6997068},{"sourceId":11219022,"sourceType":"datasetVersion","datasetId":7006240},{"sourceId":11219272,"sourceType":"datasetVersion","datasetId":7006413}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/nickxir12/MyCLIP_first_repo.git /kaggle/working/open-clip","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:47:54.275005Z","iopub.execute_input":"2025-03-30T19:47:54.275295Z","iopub.status.idle":"2025-03-30T19:47:55.944326Z","shell.execute_reply.started":"2025-03-30T19:47:54.275260Z","shell.execute_reply":"2025-03-30T19:47:55.943247Z"}},"outputs":[{"name":"stdout","text":"Cloning into '/kaggle/working/open-clip'...\nremote: Enumerating objects: 3693, done.\u001b[K\nremote: Counting objects: 100% (3693/3693), done.\u001b[K\nremote: Compressing objects: 100% (1422/1422), done.\u001b[K\nremote: Total 3693 (delta 2238), reused 3624 (delta 2169), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (3693/3693), 16.75 MiB | 31.42 MiB/s, done.\nResolving deltas: 100% (2238/2238), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Step 1: Delete the old repo (if it exists)\n!rm -rf /kaggle/working/open-clip  \n\n# Step 2: Clone the latest version from GitHub\n!git clone https://github.com/nickxir12/MyCLIP_first_repo.git /kaggle/working/open-clip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:28:01.305658Z","iopub.execute_input":"2025-03-30T20:28:01.306053Z","iopub.status.idle":"2025-03-30T20:28:02.801504Z","shell.execute_reply.started":"2025-03-30T20:28:01.306023Z","shell.execute_reply":"2025-03-30T20:28:02.800282Z"}},"outputs":[{"name":"stdout","text":"Cloning into '/kaggle/working/open-clip'...\nremote: Enumerating objects: 3731, done.\u001b[K\nremote: Counting objects: 100% (3731/3731), done.\u001b[K\nremote: Compressing objects: 100% (1454/1454), done.\u001b[K\nremote: Total 3731 (delta 2262), reused 3644 (delta 2175), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (3731/3731), 16.76 MiB | 35.75 MiB/s, done.\nResolving deltas: 100% (2262/2262), done.\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"#!pip install open_clip_torch\n!pip install braceexpand\n!pip install webdataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:47:57.496276Z","iopub.execute_input":"2025-03-30T19:47:57.496639Z","iopub.status.idle":"2025-03-30T19:48:06.255787Z","shell.execute_reply.started":"2025-03-30T19:47:57.496601Z","shell.execute_reply":"2025-03-30T19:48:06.254607Z"}},"outputs":[{"name":"stdout","text":"Collecting braceexpand\n  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\nDownloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\nInstalling collected packages: braceexpand\nSuccessfully installed braceexpand-0.1.7\nCollecting webdataset\n  Downloading webdataset-0.2.111-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (from webdataset) (0.1.7)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from webdataset) (1.26.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from webdataset) (6.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->webdataset) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->webdataset) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->webdataset) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->webdataset) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->webdataset) (2024.2.0)\nDownloading webdataset-0.2.111-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: webdataset\nSuccessfully installed webdataset-0.2.111\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install -r /kaggle/working/open-clip/requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:06.258361Z","iopub.execute_input":"2025-03-30T19:48:06.258652Z","iopub.status.idle":"2025-03-30T19:48:10.150182Z","shell.execute_reply.started":"2025-03-30T19:48:06.258627Z","shell.execute_reply":"2025-03-30T19:48:10.149334Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 1)) (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 2)) (0.20.1+cu121)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 3)) (2024.11.6)\nCollecting ftfy (from -r /kaggle/working/open-clip/requirements.txt (line 4))\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 5)) (4.67.1)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 6)) (0.29.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 7)) (0.4.5)\nRequirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 8)) (1.0.12)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (11.0.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->-r /kaggle/working/open-clip/requirements.txt (line 4)) (0.2.13)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (2.32.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2024.2.0)\nDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: ftfy\nSuccessfully installed ftfy-6.3.1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport sys\nsys.path.append(\"/kaggle/working/open-clip/src\")\nsys.path.append(\"/kaggle/working/open-clip/src/open_clip\")\nsys.path.append(\"/kaggle/working/open-clip/src/open_clip_train/my_metrics\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:10.152076Z","iopub.execute_input":"2025-03-30T19:48:10.152388Z","iopub.status.idle":"2025-03-30T19:48:10.156365Z","shell.execute_reply.started":"2025-03-30T19:48:10.152359Z","shell.execute_reply":"2025-03-30T19:48:10.155722Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# import importlib\n# import my_metrics\n# importlib.reload(my_metrics)\n# print(dir(my_metrics))  # Now should include 'batch', 'get_all_embeddings', etc.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:10.157155Z","iopub.execute_input":"2025-03-30T19:48:10.157446Z","iopub.status.idle":"2025-03-30T19:48:10.168152Z","shell.execute_reply.started":"2025-03-30T19:48:10.157418Z","shell.execute_reply":"2025-03-30T19:48:10.167481Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from my_metrics import compute_consistency_score,evaluate_model\n\n#Does below work?\nfrom my_metrics import batch,get_all_embeddings,itm_eval,compute_consistency_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:51:46.396412Z","iopub.execute_input":"2025-03-30T19:51:46.396796Z","iopub.status.idle":"2025-03-30T19:51:46.401833Z","shell.execute_reply.started":"2025-03-30T19:51:46.396766Z","shell.execute_reply":"2025-03-30T19:51:46.400428Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"import open_clip\nimport open_clip_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:13.769384Z","iopub.execute_input":"2025-03-30T19:48:13.769910Z","iopub.status.idle":"2025-03-30T19:48:22.208918Z","shell.execute_reply.started":"2025-03-30T19:48:13.769875Z","shell.execute_reply":"2025-03-30T19:48:22.207917Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nimport json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:22.209775Z","iopub.execute_input":"2025-03-30T19:48:22.210023Z","iopub.status.idle":"2025-03-30T19:48:22.214447Z","shell.execute_reply.started":"2025-03-30T19:48:22.210004Z","shell.execute_reply":"2025-03-30T19:48:22.213054Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch\nimport os\nimport open_clip\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:22.215500Z","iopub.execute_input":"2025-03-30T19:48:22.215854Z","iopub.status.idle":"2025-03-30T19:48:22.309432Z","shell.execute_reply.started":"2025-03-30T19:48:22.215820Z","shell.execute_reply":"2025-03-30T19:48:22.308504Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#open_clip.list_pretrained()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:22.310275Z","iopub.execute_input":"2025-03-30T19:48:22.310574Z","iopub.status.idle":"2025-03-30T19:48:22.314029Z","shell.execute_reply.started":"2025-03-30T19:48:22.310538Z","shell.execute_reply":"2025-03-30T19:48:22.313032Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"#                Preparing train datasaet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:22.314847Z","iopub.execute_input":"2025-03-30T19:48:22.315082Z","iopub.status.idle":"2025-03-30T19:48:22.325331Z","shell.execute_reply.started":"2025-03-30T19:48:22.315052Z","shell.execute_reply":"2025-03-30T19:48:22.324426Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import json\nimport pandas as pd\n\n# Load Karpathy JSON file\nkarpathy_json_path = \"/kaggle/input/karpathy-splits/dataset_flickr30k.json\"\nwith open(karpathy_json_path, \"r\") as f:\n    karpathy_data = json.load(f)\n\n# Extract training set\ntrain_data = [item for item in karpathy_data[\"images\"] if item[\"split\"] == \"train\"]\n\n# Prepare data for CSV\ntrain_records = []\nfor item in train_data:\n    img_filename = f\"/kaggle/input/flickr30k/Images/{item['filename']}\"\n    for sentence in item[\"sentences\"]:\n        caption = sentence[\"raw\"]\n        train_records.append({\"image\": img_filename, \"caption\": caption})\n\n# Convert to DataFrame\ndf_train = pd.DataFrame(train_records)\n\n# Save to CSV (formatted properly)\ncsv_path = \"/kaggle/working/train_data_karpathy.csv\"\ndf_train.to_csv(csv_path, index=True, index_label=\"id\")\n\nprint(f\"✅ CSV file saved at: {csv_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:22.329155Z","iopub.execute_input":"2025-03-30T19:48:22.329364Z","iopub.status.idle":"2025-03-30T19:48:24.909398Z","shell.execute_reply.started":"2025-03-30T19:48:22.329346Z","shell.execute_reply":"2025-03-30T19:48:24.908420Z"}},"outputs":[{"name":"stdout","text":"✅ CSV file saved at: /kaggle/working/train_data_karpathy.csv\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:24.911190Z","iopub.execute_input":"2025-03-30T19:48:24.911428Z","iopub.status.idle":"2025-03-30T19:48:24.933232Z","shell.execute_reply.started":"2025-03-30T19:48:24.911406Z","shell.execute_reply":"2025-03-30T19:48:24.932395Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                           image  \\\n0  /kaggle/input/flickr30k/Images/1000092795.jpg   \n1  /kaggle/input/flickr30k/Images/1000092795.jpg   \n2  /kaggle/input/flickr30k/Images/1000092795.jpg   \n3  /kaggle/input/flickr30k/Images/1000092795.jpg   \n4  /kaggle/input/flickr30k/Images/1000092795.jpg   \n\n                                             caption  \n0  Two young guys with shaggy hair look at their ...  \n1  Two young, White males are outside near many b...  \n2    Two men in green shirts are standing in a yard.  \n3        A man in a blue shirt standing in a garden.  \n4             Two friends enjoy time spent together.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n      <td>Two young guys with shaggy hair look at their ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n      <td>Two young, White males are outside near many b...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n      <td>Two men in green shirts are standing in a yard.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n      <td>A man in a blue shirt standing in a garden.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n      <td>Two friends enjoy time spent together.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"karpathy_json_path = \"/kaggle/input/karpathy-splits/dataset_flickr30k.json\"\nwith open(karpathy_json_path, \"r\") as f:\n    karpathy_data = json.load(f)\n\n# Extract test set\ntest_data = [item for item in karpathy_data[\"images\"] if item[\"split\"] == \"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:24.934048Z","iopub.execute_input":"2025-03-30T19:48:24.934309Z","iopub.status.idle":"2025-03-30T19:48:26.196290Z","shell.execute_reply.started":"2025-03-30T19:48:24.934288Z","shell.execute_reply":"2025-03-30T19:48:26.195531Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:26.197034Z","iopub.execute_input":"2025-03-30T19:48:26.197288Z","iopub.status.idle":"2025-03-30T19:48:26.272603Z","shell.execute_reply.started":"2025-03-30T19:48:26.197266Z","shell.execute_reply":"2025-03-30T19:48:26.271518Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"#Standard loading\n# model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n# model = model.to(device)\n# model.eval()  # model in train mode by default, impacts some models with BatchNorm or stochastic depth active\n# tokenizer = open_clip.get_tokenizer('ViT-B-32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:26.273728Z","iopub.execute_input":"2025-03-30T19:48:26.274096Z","iopub.status.idle":"2025-03-30T19:48:26.284133Z","shell.execute_reply.started":"2025-03-30T19:48:26.274071Z","shell.execute_reply":"2025-03-30T19:48:26.283371Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# # FOR CYCLIP PRE TRAINED THAT I HAVE DOWNLOADED LOCALLY\n# model_clip_3M, _, preprocess = open_clip.create_model_and_transforms(\n#     model_name=\"RN50\",\n#     pretrained=None,  # Don't load default weights\n#     precision='fp32', # or 'amp' for mixed precision\n#     device=device\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:26.285008Z","iopub.execute_input":"2025-03-30T19:48:26.285353Z","iopub.status.idle":"2025-03-30T19:48:26.296732Z","shell.execute_reply.started":"2025-03-30T19:48:26.285330Z","shell.execute_reply":"2025-03-30T19:48:26.295856Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# # Load the checkpoint - OG CLIP - 3M\n# ckpt = torch.load(\"/kaggle/input/clip-3m-from-cyclip/clip-3M.pt/best.pt\", map_location=device)\n# state_dict = ckpt[\"state_dict\"]\n\n# # Remove 'module.' prefix from keys\n# new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n\n# # Load into your model\n# model_clip_3M.load_state_dict(new_state_dict)\n# model_clip_3M.to(device)\n# model_clip_3M.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:26.297616Z","iopub.execute_input":"2025-03-30T19:48:26.297882Z","iopub.status.idle":"2025-03-30T19:48:26.308852Z","shell.execute_reply.started":"2025-03-30T19:48:26.297860Z","shell.execute_reply":"2025-03-30T19:48:26.308029Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# FOR CYCLIP PRE TRAINED THAT I HAVE DOWNLOADED LOCALLY\n# model_Cyclip_3M, _, preprocess = open_clip.create_model_and_transforms(\n#     model_name=\"RN50\",\n#     pretrained=None,  # Don't load default weights\n#     precision='fp32', # or 'amp' for mixed precision\n#     device=device\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:26.309724Z","iopub.execute_input":"2025-03-30T19:48:26.309980Z","iopub.status.idle":"2025-03-30T19:48:26.324228Z","shell.execute_reply.started":"2025-03-30T19:48:26.309957Z","shell.execute_reply":"2025-03-30T19:48:26.323282Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# # Load the checkpoint - CY CLIP - 3M\n# ckpt = torch.load(\"/kaggle/input/cyclip-3m/CYCLIP-3M_best.pt\", map_location=device)\n# state_dict = ckpt[\"state_dict\"]\n\n# # Remove 'module.' prefix from keys\n# new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n\n# # Load into your model\n# model_Cyclip_3M.load_state_dict(new_state_dict)\n# model_Cyclip_3M.to(device)\n# model_Cyclip_3M.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:26.325265Z","iopub.execute_input":"2025-03-30T19:48:26.325595Z","iopub.status.idle":"2025-03-30T19:48:26.335621Z","shell.execute_reply.started":"2025-03-30T19:48:26.325563Z","shell.execute_reply":"2025-03-30T19:48:26.334918Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"#Tokenizer for my models\ntokenizer = open_clip.get_tokenizer('RN50')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:26.336486Z","iopub.execute_input":"2025-03-30T19:48:26.336793Z","iopub.status.idle":"2025-03-30T19:48:26.460622Z","shell.execute_reply.started":"2025-03-30T19:48:26.336763Z","shell.execute_reply":"2025-03-30T19:48:26.459611Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"#FOR CYCLIP PRE TRAINED THAT I HAVE DOWNLOADED LOCALLY\nmodel_clip_final, _, preprocess = open_clip.create_model_and_transforms(\n    model_name=\"RN50\",\n    pretrained=None,  # Don't load default weights\n    precision='fp32', # or 'amp' for mixed precision\n    device=device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:48:35.030574Z","iopub.execute_input":"2025-03-30T19:48:35.030913Z","iopub.status.idle":"2025-03-30T19:48:36.918640Z","shell.execute_reply.started":"2025-03-30T19:48:35.030883Z","shell.execute_reply":"2025-03-30T19:48:36.917872Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Load the checkpoint - CLIP - Final\nckpt = torch.load(\"/kaggle/input/clip-final/clip_best.pt\", map_location=device)\nstate_dict = ckpt[\"state_dict\"]\n\n# Remove 'module.' prefix from keys\nnew_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n\n# Load into your model\nmodel_clip_final.load_state_dict(new_state_dict)\nmodel_clip_final.to(device)\nmodel_clip_final.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:04:24.701802Z","iopub.execute_input":"2025-03-30T20:04:24.702276Z","iopub.status.idle":"2025-03-30T20:04:25.747911Z","shell.execute_reply.started":"2025-03-30T20:04:24.702238Z","shell.execute_reply":"2025-03-30T20:04:25.747020Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-48-74080bc77d25>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(\"/kaggle/input/clip-final/clip_best.pt\", map_location=device)\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"CLIP(\n  (visual): ModifiedResNet(\n    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act2): ReLU(inplace=True)\n    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (attnpool): AttentionPool2d(\n      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n    )\n  )\n  (transformer): Transformer(\n    (resblocks): ModuleList(\n      (0-11): 12 x ResidualAttentionBlock(\n        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (ls_1): Identity()\n        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n          (gelu): GELU(approximate='none')\n          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (ls_2): Identity()\n      )\n    )\n  )\n  (token_embedding): Embedding(49408, 512)\n  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n)"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"torch.save(new_state_dict, '/kaggle/working/clip_final.pt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:04:30.724967Z","iopub.execute_input":"2025-03-30T20:04:30.725308Z","iopub.status.idle":"2025-03-30T20:04:31.337315Z","shell.execute_reply.started":"2025-03-30T20:04:30.725279Z","shell.execute_reply":"2025-03-30T20:04:31.336378Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"#FOR CYCLIP PRE TRAINED THAT I HAVE DOWNLOADED LOCALLY\nmodel_Cyclip_final, _, preprocess = open_clip.create_model_and_transforms(\n    model_name=\"RN50\",\n    pretrained=None,  # Don't load default weights\n    precision='fp32', # or 'amp' for mixed precision\n    device=device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:04:37.829892Z","iopub.execute_input":"2025-03-30T20:04:37.830251Z","iopub.status.idle":"2025-03-30T20:04:39.148086Z","shell.execute_reply.started":"2025-03-30T20:04:37.830221Z","shell.execute_reply":"2025-03-30T20:04:39.147407Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# Load the checkpoint - CY CLIP - Final\nckpt = torch.load(\"/kaggle/input/cyclip-final/cyclip_best.pt\", map_location=device)\nstate_dict = ckpt[\"state_dict\"]\n\n# Remove 'module.' prefix from keys\nnew_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n\n# Load into your model\nmodel_Cyclip_final.load_state_dict(new_state_dict)\nmodel_Cyclip_final.to(device)\nmodel_Cyclip_final.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:04:39.251622Z","iopub.execute_input":"2025-03-30T20:04:39.251949Z","iopub.status.idle":"2025-03-30T20:04:40.309612Z","shell.execute_reply.started":"2025-03-30T20:04:39.251922Z","shell.execute_reply":"2025-03-30T20:04:40.308881Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-51-681b61487b99>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(\"/kaggle/input/cyclip-final/cyclip_best.pt\", map_location=device)\n","output_type":"stream"},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"CLIP(\n  (visual): ModifiedResNet(\n    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act2): ReLU(inplace=True)\n    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (attnpool): AttentionPool2d(\n      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n    )\n  )\n  (transformer): Transformer(\n    (resblocks): ModuleList(\n      (0-11): 12 x ResidualAttentionBlock(\n        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (ls_1): Identity()\n        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n          (gelu): GELU(approximate='none')\n          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (ls_2): Identity()\n      )\n    )\n  )\n  (token_embedding): Embedding(49408, 512)\n  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n)"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"torch.save(new_state_dict, '/kaggle/working/Cyclip_final.pt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:04:50.161692Z","iopub.execute_input":"2025-03-30T20:04:50.161987Z","iopub.status.idle":"2025-03-30T20:04:50.758609Z","shell.execute_reply.started":"2025-03-30T20:04:50.161963Z","shell.execute_reply":"2025-03-30T20:04:50.757927Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# open_clip.list_pretrained()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:49:02.050098Z","iopub.execute_input":"2025-03-30T19:49:02.050378Z","iopub.status.idle":"2025-03-30T19:49:02.053932Z","shell.execute_reply.started":"2025-03-30T19:49:02.050355Z","shell.execute_reply":"2025-03-30T19:49:02.053206Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"#                Models loaded are model_Cyclip_final and model_clip_final\n#                Will further fine them below\n                    # Will fine tune\n                    #     --> as usual\n                    #     --> with Dino regularizor","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#          TO FINE TUNE\n!python /kaggle/working/open-clip/src/open_clip_train/main.py \\\n    --train-data /kaggle/working/train_data_karpathy.csv \\\n    --name 'og_fine_tuned_Clip_1_epoch' \\\n    --dataset-type csv \\\n    --csv-img-key image \\\n    --csv-caption-key caption \\\n    --csv-separator \",\" \\\n    --model RN50  \\\n    --pretrained /kaggle/working/clip_final.pt \\\n    --batch-size 48 \\\n    --lr 5e-6 \\\n    --warmup 1000 \\\n    --epochs 1 \\\n    --lr-scheduler cosine \\\n    --precision amp \\\n    --workers 4 \\\n    --logs \"logs\" \\\n    --logs \"checkpoints\" \\\n    --save-frequency 1 \\\n    --seed 42 \\\n\n    #--lambda_dino 0.25 \\\n    #--use_soft_labels \\\n    #--soft_temprature 0.05 \\\n    #--alpha 0  \\\n    #use_dino_reg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:28:18.592501Z","iopub.execute_input":"2025-03-30T20:28:18.592866Z","iopub.status.idle":"2025-03-30T20:48:26.218217Z","shell.execute_reply.started":"2025-03-30T20:28:18.592827Z","shell.execute_reply":"2025-03-30T20:48:26.217007Z"}},"outputs":[{"name":"stdout","text":"2025-03-30 20:28:22.037817: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-30 20:28:22.057658: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-30 20:28:22.063557: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nUsing device: cuda\n['/kaggle/working/open-clip/src/open_clip_train/main.py', '--train-data', '/kaggle/working/train_data_karpathy.csv', '--name', 'og_fine_tuned_Clip_1_epoch', '--dataset-type', 'csv', '--csv-img-key', 'image', '--csv-caption-key', 'caption', '--csv-separator', ',', '--model', 'RN50', '--pretrained', '/kaggle/working/clip_final.pt', '--batch-size', '48', '--lr', '5e-6', '--warmup', '1000', '--epochs', '1', '--lr-scheduler', 'cosine', '--precision', 'amp', '--workers', '4', '--logs', 'logs', '--logs', 'checkpoints', '--save-frequency', '1', '--seed', '42']\nuse_soft_labels: False\nalpha: 0.5\n2025-03-30,20:28:27 | INFO | Running with a single process. Device cuda.\n2025-03-30,20:28:27 | INFO | Loaded RN50 model config.\n2025-03-30,20:28:28 | INFO | Loading pretrained RN50 weights (/kaggle/working/clip_final.pt).\n2025-03-30,20:28:29 | INFO | Model:\n2025-03-30,20:28:29 | INFO | CLIP(\n  (visual): ModifiedResNet(\n    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act2): ReLU(inplace=True)\n    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (attnpool): AttentionPool2d(\n      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n    )\n  )\n  (transformer): Transformer(\n    (resblocks): ModuleList(\n      (0-11): 12 x ResidualAttentionBlock(\n        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (ls_1): Identity()\n        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n          (gelu): GELU(approximate='none')\n          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (ls_2): Identity()\n      )\n    )\n  )\n  (token_embedding): Embedding(49408, 512)\n  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n)\n2025-03-30,20:28:29 | INFO | Params:\n2025-03-30,20:28:29 | INFO |   accum_freq: 1\n2025-03-30,20:28:29 | INFO |   alpha: 0.5\n2025-03-30,20:28:29 | INFO |   aug_cfg: {}\n2025-03-30,20:28:29 | INFO |   batch_size: 48\n2025-03-30,20:28:29 | INFO |   beta1: 0.9\n2025-03-30,20:28:29 | INFO |   beta2: 0.999\n2025-03-30,20:28:29 | INFO |   cache_dir: None\n2025-03-30,20:28:29 | INFO |   checkpoint_path: checkpoints/og_fine_tuned_Clip_1_epoch/checkpoints\n2025-03-30,20:28:29 | INFO |   coca_caption_loss_weight: 2.0\n2025-03-30,20:28:29 | INFO |   coca_contrastive_loss_weight: 1.0\n2025-03-30,20:28:29 | INFO |   copy_codebase: False\n2025-03-30,20:28:29 | INFO |   csv_caption_key: caption\n2025-03-30,20:28:29 | INFO |   csv_img_key: image\n2025-03-30,20:28:29 | INFO |   csv_separator: ,\n2025-03-30,20:28:29 | INFO |   dataset_resampled: False\n2025-03-30,20:28:29 | INFO |   dataset_type: csv\n2025-03-30,20:28:29 | INFO |   ddp_static_graph: False\n2025-03-30,20:28:29 | INFO |   debug: False\n2025-03-30,20:28:29 | INFO |   delete_previous_checkpoint: False\n2025-03-30,20:28:29 | INFO |   device: cuda\n2025-03-30,20:28:29 | INFO |   dist_backend: None\n2025-03-30,20:28:29 | INFO |   dist_url: None\n2025-03-30,20:28:29 | INFO |   distill: False\n2025-03-30,20:28:29 | INFO |   distill_model: None\n2025-03-30,20:28:29 | INFO |   distill_pretrained: None\n2025-03-30,20:28:29 | INFO |   distributed: False\n2025-03-30,20:28:29 | INFO |   enforce_to_text: False\n2025-03-30,20:28:29 | INFO |   epochs: 1\n2025-03-30,20:28:29 | INFO |   epochs_cooldown: None\n2025-03-30,20:28:29 | INFO |   eps: 1e-08\n2025-03-30,20:28:29 | INFO |   force_custom_text: False\n2025-03-30,20:28:29 | INFO |   force_image_size: None\n2025-03-30,20:28:29 | INFO |   force_patch_dropout: None\n2025-03-30,20:28:29 | INFO |   force_quick_gelu: False\n2025-03-30,20:28:29 | INFO |   gather_with_grad: False\n2025-03-30,20:28:29 | INFO |   grad_checkpointing: False\n2025-03-30,20:28:29 | INFO |   grad_clip_norm: None\n2025-03-30,20:28:29 | INFO |   horovod: False\n2025-03-30,20:28:29 | INFO |   image_interpolation: None\n2025-03-30,20:28:29 | INFO |   image_mean: None\n2025-03-30,20:28:29 | INFO |   image_resize_mode: None\n2025-03-30,20:28:29 | INFO |   image_std: None\n2025-03-30,20:28:29 | INFO |   imagenet_v2: None\n2025-03-30,20:28:29 | INFO |   imagenet_val: None\n2025-03-30,20:28:29 | INFO |   lambda_dino: 0.1\n2025-03-30,20:28:29 | INFO |   local_loss: False\n2025-03-30,20:28:29 | INFO |   local_rank: 0\n2025-03-30,20:28:29 | INFO |   lock_image: False\n2025-03-30,20:28:29 | INFO |   lock_image_freeze_bn_stats: False\n2025-03-30,20:28:29 | INFO |   lock_image_unlocked_groups: 0\n2025-03-30,20:28:29 | INFO |   lock_text: False\n2025-03-30,20:28:29 | INFO |   lock_text_freeze_layer_norm: False\n2025-03-30,20:28:29 | INFO |   lock_text_unlocked_layers: 0\n2025-03-30,20:28:29 | INFO |   log_every_n_steps: 100\n2025-03-30,20:28:29 | INFO |   log_level: 20\n2025-03-30,20:28:29 | INFO |   log_local: False\n2025-03-30,20:28:29 | INFO |   log_path: checkpoints/og_fine_tuned_Clip_1_epoch/out.log\n2025-03-30,20:28:29 | INFO |   logs: checkpoints\n2025-03-30,20:28:29 | INFO |   loss_dist_impl: None\n2025-03-30,20:28:29 | INFO |   lr: 5e-06\n2025-03-30,20:28:29 | INFO |   lr_cooldown_end: 0.0\n2025-03-30,20:28:29 | INFO |   lr_cooldown_power: 1.0\n2025-03-30,20:28:29 | INFO |   lr_scheduler: cosine\n2025-03-30,20:28:29 | INFO |   model: RN50\n2025-03-30,20:28:29 | INFO |   momentum: None\n2025-03-30,20:28:29 | INFO |   name: og_fine_tuned_Clip_1_epoch\n2025-03-30,20:28:29 | INFO |   no_set_device_rank: False\n2025-03-30,20:28:29 | INFO |   opt: adamw\n2025-03-30,20:28:29 | INFO |   precision: amp\n2025-03-30,20:28:29 | INFO |   pretrained: /kaggle/working/clip_final.pt\n2025-03-30,20:28:29 | INFO |   pretrained_image: False\n2025-03-30,20:28:29 | INFO |   rank: 0\n2025-03-30,20:28:29 | INFO |   remote_sync: None\n2025-03-30,20:28:29 | INFO |   remote_sync_frequency: 300\n2025-03-30,20:28:29 | INFO |   remote_sync_protocol: s3\n2025-03-30,20:28:29 | INFO |   report_to: \n2025-03-30,20:28:29 | INFO |   resume: None\n2025-03-30,20:28:29 | INFO |   save_frequency: 1\n2025-03-30,20:28:29 | INFO |   save_most_recent: False\n2025-03-30,20:28:29 | INFO |   seed: 42\n2025-03-30,20:28:29 | INFO |   siglip: False\n2025-03-30,20:28:29 | INFO |   skip_scheduler: False\n2025-03-30,20:28:29 | INFO |   soft_temprature: 0.02\n2025-03-30,20:28:29 | INFO |   tensorboard: False\n2025-03-30,20:28:29 | INFO |   tensorboard_path: \n2025-03-30,20:28:29 | INFO |   torchcompile: False\n2025-03-30,20:28:29 | INFO |   torchscript: False\n2025-03-30,20:28:29 | INFO |   trace: False\n2025-03-30,20:28:29 | INFO |   train_data: /kaggle/working/train_data_karpathy.csv\n2025-03-30,20:28:29 | INFO |   train_data_upsampling_factors: None\n2025-03-30,20:28:29 | INFO |   train_num_samples: None\n2025-03-30,20:28:29 | INFO |   use_bn_sync: False\n2025-03-30,20:28:29 | INFO |   use_bnb_linear: None\n2025-03-30,20:28:29 | INFO |   use_dino_reg: False\n2025-03-30,20:28:29 | INFO |   use_soft_labels: False\n2025-03-30,20:28:29 | INFO |   val_data: None\n2025-03-30,20:28:29 | INFO |   val_frequency: 1\n2025-03-30,20:28:29 | INFO |   val_num_samples: None\n2025-03-30,20:28:29 | INFO |   wandb: False\n2025-03-30,20:28:29 | INFO |   wandb_notes: \n2025-03-30,20:28:29 | INFO |   wandb_project_name: open-clip\n2025-03-30,20:28:29 | INFO |   warmup: 1000\n2025-03-30,20:28:29 | INFO |   wd: 0.2\n2025-03-30,20:28:29 | INFO |   workers: 4\n2025-03-30,20:28:29 | INFO |   world_size: 1\n2025-03-30,20:28:29 | INFO |   zeroshot_frequency: 2\n2025-03-30,20:28:29 | INFO | Created AdamW (adamw) optimizer: lr: 5e-06, betas: (0.9, 0.999), eps: 1e-08, weight_decay: 0.2, amsgrad: False, foreach: None, maximize: False, capturable: False, differentiable: False, fused: None\n2025-03-30,20:28:29 | INFO | Start epoch 0\n2025-03-30,20:28:35 | INFO | Train Epoch: 0 [    48/145000 (0%)] Data (t): 1.162 Batch (t): 5.775, 8.31191/s, 8.31191/s/gpu LR: 0.000000 Logit Scale: 73.816 Original_clip_loss: 1.6901 (1.6901) Loss: 1.6901 (1.6901)\n2025-03-30,20:29:16 | INFO | Train Epoch: 0 [  4848/145000 (3%)] Data (t): 0.000 Batch (t): 0.409, 125.959/s, 125.959/s/gpu LR: 0.000001 Logit Scale: 73.814 Original_clip_loss: 1.6625 (1.6763) Loss: 1.6625 (1.6763)\n2025-03-30,20:29:54 | INFO | Train Epoch: 0 [  9648/145000 (7%)] Data (t): 0.001 Batch (t): 0.387, 121.320/s, 121.320/s/gpu LR: 0.000001 Logit Scale: 73.809 Original_clip_loss: 1.5425 (1.6317) Loss: 1.5425 (1.6317)\n2025-03-30,20:30:34 | INFO | Train Epoch: 0 [ 14448/145000 (10%)] Data (t): 0.001 Batch (t): 0.397, 122.252/s, 122.252/s/gpu LR: 0.000002 Logit Scale: 73.801 Original_clip_loss: 1.5516 (1.6116) Loss: 1.5516 (1.6116)\n2025-03-30,20:31:13 | INFO | Train Epoch: 0 [ 19248/145000 (13%)] Data (t): 0.001 Batch (t): 0.392, 123.424/s, 123.424/s/gpu LR: 0.000002 Logit Scale: 73.790 Original_clip_loss: 1.8359 (1.6565) Loss: 1.8359 (1.6565)\n2025-03-30,20:31:52 | INFO | Train Epoch: 0 [ 24048/145000 (17%)] Data (t): 0.001 Batch (t): 0.392, 120.503/s, 120.503/s/gpu LR: 0.000003 Logit Scale: 73.776 Original_clip_loss: 1.6457 (1.6547) Loss: 1.6457 (1.6547)\n2025-03-30,20:32:32 | INFO | Train Epoch: 0 [ 28848/145000 (20%)] Data (t): 0.001 Batch (t): 0.392, 123.490/s, 123.490/s/gpu LR: 0.000003 Logit Scale: 73.760 Original_clip_loss: 1.3845 (1.6161) Loss: 1.3845 (1.6161)\n2025-03-30,20:33:11 | INFO | Train Epoch: 0 [ 33648/145000 (23%)] Data (t): 0.001 Batch (t): 0.391, 120.994/s, 120.994/s/gpu LR: 0.000004 Logit Scale: 73.742 Original_clip_loss: 0.99459 (1.5384) Loss: 0.99459 (1.5384)\n2025-03-30,20:33:50 | INFO | Train Epoch: 0 [ 38448/145000 (27%)] Data (t): 0.001 Batch (t): 0.393, 120.202/s, 120.202/s/gpu LR: 0.000004 Logit Scale: 73.723 Original_clip_loss: 1.0852 (1.4880) Loss: 1.0852 (1.4880)\n2025-03-30,20:34:30 | INFO | Train Epoch: 0 [ 43248/145000 (30%)] Data (t): 0.001 Batch (t): 0.394, 121.837/s, 121.837/s/gpu LR: 0.000005 Logit Scale: 73.702 Original_clip_loss: 1.2628 (1.4655) Loss: 1.2628 (1.4655)\n2025-03-30,20:35:09 | INFO | Train Epoch: 0 [ 48048/145000 (33%)] Data (t): 0.001 Batch (t): 0.392, 122.466/s, 122.466/s/gpu LR: 0.000005 Logit Scale: 73.682 Original_clip_loss: 0.80958 (1.4059) Loss: 0.80958 (1.4059)\n2025-03-30,20:35:48 | INFO | Train Epoch: 0 [ 52848/145000 (36%)] Data (t): 0.001 Batch (t): 0.392, 122.216/s, 122.216/s/gpu LR: 0.000005 Logit Scale: 73.661 Original_clip_loss: 1.0329 (1.3748) Loss: 1.0329 (1.3748)\n2025-03-30,20:36:27 | INFO | Train Epoch: 0 [ 57648/145000 (40%)] Data (t): 0.001 Batch (t): 0.392, 122.065/s, 122.065/s/gpu LR: 0.000005 Logit Scale: 73.645 Original_clip_loss: 0.75711 (1.3273) Loss: 0.75711 (1.3273)\n2025-03-30,20:37:06 | INFO | Train Epoch: 0 [ 62448/145000 (43%)] Data (t): 0.001 Batch (t): 0.393, 119.271/s, 119.271/s/gpu LR: 0.000005 Logit Scale: 73.629 Original_clip_loss: 0.77457 (1.2878) Loss: 0.77457 (1.2878)\n2025-03-30,20:37:46 | INFO | Train Epoch: 0 [ 67248/145000 (46%)] Data (t): 0.001 Batch (t): 0.393, 123.516/s, 123.516/s/gpu LR: 0.000005 Logit Scale: 73.616 Original_clip_loss: 0.81157 (1.2561) Loss: 0.81157 (1.2561)\n2025-03-30,20:38:25 | INFO | Train Epoch: 0 [ 72048/145000 (50%)] Data (t): 0.001 Batch (t): 0.394, 122.215/s, 122.215/s/gpu LR: 0.000004 Logit Scale: 73.604 Original_clip_loss: 0.82823 (1.2293) Loss: 0.82823 (1.2293)\n2025-03-30,20:39:04 | INFO | Train Epoch: 0 [ 76848/145000 (53%)] Data (t): 0.001 Batch (t): 0.394, 120.815/s, 120.815/s/gpu LR: 0.000004 Logit Scale: 73.593 Original_clip_loss: 0.83880 (1.2064) Loss: 0.83880 (1.2064)\n2025-03-30,20:39:44 | INFO | Train Epoch: 0 [ 81648/145000 (56%)] Data (t): 0.001 Batch (t): 0.394, 123.061/s, 123.061/s/gpu LR: 0.000004 Logit Scale: 73.584 Original_clip_loss: 0.89855 (1.1893) Loss: 0.89855 (1.1893)\n2025-03-30,20:40:23 | INFO | Train Epoch: 0 [ 86448/145000 (60%)] Data (t): 0.001 Batch (t): 0.394, 121.284/s, 121.284/s/gpu LR: 0.000003 Logit Scale: 73.575 Original_clip_loss: 0.85421 (1.1716) Loss: 0.85421 (1.1716)\n2025-03-30,20:41:02 | INFO | Train Epoch: 0 [ 91248/145000 (63%)] Data (t): 0.001 Batch (t): 0.392, 122.535/s, 122.535/s/gpu LR: 0.000003 Logit Scale: 73.568 Original_clip_loss: 0.38918 (1.1325) Loss: 0.38918 (1.1325)\n2025-03-30,20:41:42 | INFO | Train Epoch: 0 [ 96048/145000 (66%)] Data (t): 0.001 Batch (t): 0.392, 122.821/s, 122.821/s/gpu LR: 0.000003 Logit Scale: 73.562 Original_clip_loss: 0.58360 (1.1064) Loss: 0.58360 (1.1064)\n2025-03-30,20:42:21 | INFO | Train Epoch: 0 [100848/145000 (70%)] Data (t): 0.001 Batch (t): 0.392, 123.321/s, 123.321/s/gpu LR: 0.000002 Logit Scale: 73.556 Original_clip_loss: 0.70162 (1.0880) Loss: 0.70162 (1.0880)\n2025-03-30,20:43:00 | INFO | Train Epoch: 0 [105648/145000 (73%)] Data (t): 0.001 Batch (t): 0.393, 121.347/s, 121.347/s/gpu LR: 0.000002 Logit Scale: 73.552 Original_clip_loss: 0.63005 (1.0681) Loss: 0.63005 (1.0681)\n2025-03-30,20:43:40 | INFO | Train Epoch: 0 [110448/145000 (76%)] Data (t): 0.001 Batch (t): 0.394, 121.486/s, 121.486/s/gpu LR: 0.000001 Logit Scale: 73.549 Original_clip_loss: 0.66831 (1.0514) Loss: 0.66831 (1.0514)\n2025-03-30,20:44:19 | INFO | Train Epoch: 0 [115248/145000 (80%)] Data (t): 0.001 Batch (t): 0.393, 122.432/s, 122.432/s/gpu LR: 0.000001 Logit Scale: 73.545 Original_clip_loss: 0.86991 (1.0441) Loss: 0.86991 (1.0441)\n2025-03-30,20:44:58 | INFO | Train Epoch: 0 [120048/145000 (83%)] Data (t): 0.001 Batch (t): 0.392, 120.302/s, 120.302/s/gpu LR: 0.000001 Logit Scale: 73.544 Original_clip_loss: 0.58316 (1.0264) Loss: 0.58316 (1.0264)\n2025-03-30,20:45:37 | INFO | Train Epoch: 0 [124848/145000 (86%)] Data (t): 0.001 Batch (t): 0.391, 122.306/s, 122.306/s/gpu LR: 0.000001 Logit Scale: 73.543 Original_clip_loss: 0.82717 (1.0190) Loss: 0.82717 (1.0190)\n2025-03-30,20:46:16 | INFO | Train Epoch: 0 [129648/145000 (89%)] Data (t): 0.001 Batch (t): 0.392, 122.042/s, 122.042/s/gpu LR: 0.000000 Logit Scale: 73.543 Original_clip_loss: 0.65615 (1.0061) Loss: 0.65615 (1.0061)\n2025-03-30,20:46:56 | INFO | Train Epoch: 0 [134448/145000 (93%)] Data (t): 0.001 Batch (t): 0.393, 121.830/s, 121.830/s/gpu LR: 0.000000 Logit Scale: 73.543 Original_clip_loss: 1.0348 (1.0071) Loss: 1.0348 (1.0071)\n2025-03-30,20:47:35 | INFO | Train Epoch: 0 [139248/145000 (96%)] Data (t): 0.001 Batch (t): 0.394, 122.708/s, 122.708/s/gpu LR: 0.000000 Logit Scale: 73.543 Original_clip_loss: 0.77167 (0.99921) Loss: 0.77167 (0.99921)\n2025-03-30,20:48:14 | INFO | Train Epoch: 0 [144048/145000 (99%)] Data (t): 0.001 Batch (t): 0.395, 121.629/s, 121.629/s/gpu LR: 0.000000 Logit Scale: 73.543 Original_clip_loss: 0.62047 (0.98699) Loss: 0.62047 (0.98699)\n2025-03-30,20:48:22 | INFO | Train Epoch: 0 [144960/145000 (100%)] Data (t): 0.003 Batch (t): 0.395, 121.649/s, 121.649/s/gpu LR: 0.000000 Logit Scale: 73.543 Original_clip_loss: 0.70396 (0.97815) Loss: 0.70396 (0.97815)\nI0330 20:48:24.323000 536 torch/_dynamo/utils.py:399] TorchDynamo compilation metrics:\nI0330 20:48:24.323000 536 torch/_dynamo/utils.py:399] Function    Runtimes (s)\nI0330 20:48:24.323000 536 torch/_dynamo/utils.py:399] ----------  --------------\nI0330 20:48:24.328000 536 torch/_subclasses/fake_tensor.py:2423] FakeTensor cache stats:\nI0330 20:48:24.328000 536 torch/_subclasses/fake_tensor.py:2424]   cache_hits: 0\nI0330 20:48:24.328000 536 torch/_subclasses/fake_tensor.py:2425]   cache_misses: 0\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"#!rm -rf checkpoints/og_fine_tuned_Clip_1_epoch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:28:12.203387Z","iopub.execute_input":"2025-03-30T20:28:12.203742Z","iopub.status.idle":"2025-03-30T20:28:12.381447Z","shell.execute_reply.started":"2025-03-30T20:28:12.203715Z","shell.execute_reply":"2025-03-30T20:28:12.380286Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"!ls checkpoints/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:13:10.937708Z","iopub.execute_input":"2025-03-30T20:13:10.938024Z","iopub.status.idle":"2025-03-30T20:13:11.116340Z","shell.execute_reply.started":"2025-03-30T20:13:10.937999Z","shell.execute_reply":"2025-03-30T20:13:11.115259Z"}},"outputs":[{"name":"stdout","text":"og_fine_tuned_Clip_1_epoch\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"import torch\nimport open_clip\n\n# Path to your trained checkpoint\ncheckpoint_path = \"checkpoints/og_fine_tuned_Clip_1_epoch/checkpoints/epoch_1.pt\"\n\n# 1. Create the model architecture from scratch (without loading pretrained weights)\nmodel_og_fine_tuned_Clip_1_epoch, preprocess_ft, preprocess_val = open_clip.create_model_and_transforms(\n    \"RN50\", pretrained=None\n)\n\n# 2. Load the trained checkpoint manually\ncheckpoint = torch.load(checkpoint_path, map_location=\"cpu\",weights_only=True)\n\n# If the state_dict is nested under a key (like \"state_dict\"), adjust accordingly\nif \"state_dict\" in checkpoint:\n    checkpoint = checkpoint[\"state_dict\"]\n\n# Load checkpoint weights into model\nmodel_og_fine_tuned_Clip_1_epoch.load_state_dict(checkpoint, strict=False)  # Use strict=False to avoid missing keys error\n\n# 3. Move model to GPU (if available)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel_og_fine_tuned_Clip_1_epoch = model_og_fine_tuned_Clip_1_epoch.to(device)\nmodel_og_fine_tuned_Clip_1_epoch.eval()\nprint(\"Model loaded successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T22:02:38.613696Z","iopub.execute_input":"2025-03-30T22:02:38.614037Z","iopub.status.idle":"2025-03-30T22:02:41.193202Z","shell.execute_reply.started":"2025-03-30T22:02:38.614014Z","shell.execute_reply":"2025-03-30T22:02:41.192367Z"}},"outputs":[{"name":"stdout","text":"Model loaded successfully!\n","output_type":"stream"}],"execution_count":89},{"cell_type":"code","source":"#          TO FINE TUNE\n!python /kaggle/working/open-clip/src/open_clip_train/main.py \\\n    --train-data /kaggle/working/train_data_karpathy.csv \\\n    --name 'dino_fine_tuned_Clip_1_epoch' \\\n    --dataset-type csv \\\n    --csv-img-key image \\\n    --csv-caption-key caption \\\n    --csv-separator \",\" \\\n    --model RN50  \\\n    --pretrained /kaggle/working/clip_final.pt \\\n    --batch-size 48 \\\n    --lr 5e-6 \\\n    --warmup 1000 \\\n    --epochs 1 \\\n    --lr-scheduler cosine \\\n    --precision amp \\\n    --workers 4 \\\n    --logs \"logs\" \\\n    --logs \"checkpoints\" \\\n    --save-frequency 1 \\\n    --seed 42 \\\n    --lambda_dino 0.3 \\\n    --soft_temprature 0.05 \\\n    --alpha 0  \\\n    --use_dino_reg ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:58:30.913006Z","iopub.execute_input":"2025-03-30T20:58:30.913341Z","iopub.status.idle":"2025-03-30T21:53:20.892141Z","shell.execute_reply.started":"2025-03-30T20:58:30.913314Z","shell.execute_reply":"2025-03-30T21:53:20.891023Z"}},"outputs":[{"name":"stdout","text":"2025-03-30 20:58:34.362439: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-30 20:58:34.383811: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-30 20:58:34.390057: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nUsing device: cuda\n['/kaggle/working/open-clip/src/open_clip_train/main.py', '--train-data', '/kaggle/working/train_data_karpathy.csv', '--name', 'dino_fine_tuned_Clip_1_epoch', '--dataset-type', 'csv', '--csv-img-key', 'image', '--csv-caption-key', 'caption', '--csv-separator', ',', '--model', 'RN50', '--pretrained', '/kaggle/working/clip_final.pt', '--batch-size', '48', '--lr', '5e-6', '--warmup', '1000', '--epochs', '1', '--lr-scheduler', 'cosine', '--precision', 'amp', '--workers', '4', '--logs', 'logs', '--logs', 'checkpoints', '--save-frequency', '1', '--seed', '42', '--lambda_dino', '0.3', '--soft_temprature', '0.05', '--alpha', '0', '--use_dino_reg']\nuse_soft_labels: False\nalpha: 0.0\n2025-03-30,20:58:39 | INFO | Running with a single process. Device cuda.\n2025-03-30,20:58:39 | INFO | Loaded RN50 model config.\n2025-03-30,20:58:40 | INFO | Loading pretrained RN50 weights (/kaggle/working/clip_final.pt).\n2025-03-30,20:58:41 | INFO | Model:\n2025-03-30,20:58:41 | INFO | CLIP(\n  (visual): ModifiedResNet(\n    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act2): ReLU(inplace=True)\n    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (avgpool): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (attnpool): AttentionPool2d(\n      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n    )\n  )\n  (transformer): Transformer(\n    (resblocks): ModuleList(\n      (0-11): 12 x ResidualAttentionBlock(\n        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (ls_1): Identity()\n        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n          (gelu): GELU(approximate='none')\n          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (ls_2): Identity()\n      )\n    )\n  )\n  (token_embedding): Embedding(49408, 512)\n  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n)\n2025-03-30,20:58:41 | INFO | Params:\n2025-03-30,20:58:41 | INFO |   accum_freq: 1\n2025-03-30,20:58:41 | INFO |   alpha: 0.0\n2025-03-30,20:58:41 | INFO |   aug_cfg: {}\n2025-03-30,20:58:41 | INFO |   batch_size: 48\n2025-03-30,20:58:41 | INFO |   beta1: 0.9\n2025-03-30,20:58:41 | INFO |   beta2: 0.999\n2025-03-30,20:58:41 | INFO |   cache_dir: None\n2025-03-30,20:58:41 | INFO |   checkpoint_path: checkpoints/dino_fine_tuned_Clip_1_epoch/checkpoints\n2025-03-30,20:58:41 | INFO |   coca_caption_loss_weight: 2.0\n2025-03-30,20:58:41 | INFO |   coca_contrastive_loss_weight: 1.0\n2025-03-30,20:58:41 | INFO |   copy_codebase: False\n2025-03-30,20:58:41 | INFO |   csv_caption_key: caption\n2025-03-30,20:58:41 | INFO |   csv_img_key: image\n2025-03-30,20:58:41 | INFO |   csv_separator: ,\n2025-03-30,20:58:41 | INFO |   dataset_resampled: False\n2025-03-30,20:58:41 | INFO |   dataset_type: csv\n2025-03-30,20:58:41 | INFO |   ddp_static_graph: False\n2025-03-30,20:58:41 | INFO |   debug: False\n2025-03-30,20:58:41 | INFO |   delete_previous_checkpoint: False\n2025-03-30,20:58:41 | INFO |   device: cuda\n2025-03-30,20:58:41 | INFO |   dist_backend: None\n2025-03-30,20:58:41 | INFO |   dist_url: None\n2025-03-30,20:58:41 | INFO |   distill: False\n2025-03-30,20:58:41 | INFO |   distill_model: None\n2025-03-30,20:58:41 | INFO |   distill_pretrained: None\n2025-03-30,20:58:41 | INFO |   distributed: False\n2025-03-30,20:58:41 | INFO |   enforce_to_text: False\n2025-03-30,20:58:41 | INFO |   epochs: 1\n2025-03-30,20:58:41 | INFO |   epochs_cooldown: None\n2025-03-30,20:58:41 | INFO |   eps: 1e-08\n2025-03-30,20:58:41 | INFO |   force_custom_text: False\n2025-03-30,20:58:41 | INFO |   force_image_size: None\n2025-03-30,20:58:41 | INFO |   force_patch_dropout: None\n2025-03-30,20:58:41 | INFO |   force_quick_gelu: False\n2025-03-30,20:58:41 | INFO |   gather_with_grad: False\n2025-03-30,20:58:41 | INFO |   grad_checkpointing: False\n2025-03-30,20:58:41 | INFO |   grad_clip_norm: None\n2025-03-30,20:58:41 | INFO |   horovod: False\n2025-03-30,20:58:41 | INFO |   image_interpolation: None\n2025-03-30,20:58:41 | INFO |   image_mean: None\n2025-03-30,20:58:41 | INFO |   image_resize_mode: None\n2025-03-30,20:58:41 | INFO |   image_std: None\n2025-03-30,20:58:41 | INFO |   imagenet_v2: None\n2025-03-30,20:58:41 | INFO |   imagenet_val: None\n2025-03-30,20:58:41 | INFO |   lambda_dino: 0.3\n2025-03-30,20:58:41 | INFO |   local_loss: False\n2025-03-30,20:58:41 | INFO |   local_rank: 0\n2025-03-30,20:58:41 | INFO |   lock_image: False\n2025-03-30,20:58:41 | INFO |   lock_image_freeze_bn_stats: False\n2025-03-30,20:58:41 | INFO |   lock_image_unlocked_groups: 0\n2025-03-30,20:58:41 | INFO |   lock_text: False\n2025-03-30,20:58:41 | INFO |   lock_text_freeze_layer_norm: False\n2025-03-30,20:58:41 | INFO |   lock_text_unlocked_layers: 0\n2025-03-30,20:58:41 | INFO |   log_every_n_steps: 100\n2025-03-30,20:58:41 | INFO |   log_level: 20\n2025-03-30,20:58:41 | INFO |   log_local: False\n2025-03-30,20:58:41 | INFO |   log_path: checkpoints/dino_fine_tuned_Clip_1_epoch/out.log\n2025-03-30,20:58:41 | INFO |   logs: checkpoints\n2025-03-30,20:58:41 | INFO |   loss_dist_impl: None\n2025-03-30,20:58:41 | INFO |   lr: 5e-06\n2025-03-30,20:58:41 | INFO |   lr_cooldown_end: 0.0\n2025-03-30,20:58:41 | INFO |   lr_cooldown_power: 1.0\n2025-03-30,20:58:41 | INFO |   lr_scheduler: cosine\n2025-03-30,20:58:41 | INFO |   model: RN50\n2025-03-30,20:58:41 | INFO |   momentum: None\n2025-03-30,20:58:41 | INFO |   name: dino_fine_tuned_Clip_1_epoch\n2025-03-30,20:58:41 | INFO |   no_set_device_rank: False\n2025-03-30,20:58:41 | INFO |   opt: adamw\n2025-03-30,20:58:41 | INFO |   precision: amp\n2025-03-30,20:58:41 | INFO |   pretrained: /kaggle/working/clip_final.pt\n2025-03-30,20:58:41 | INFO |   pretrained_image: False\n2025-03-30,20:58:41 | INFO |   rank: 0\n2025-03-30,20:58:41 | INFO |   remote_sync: None\n2025-03-30,20:58:41 | INFO |   remote_sync_frequency: 300\n2025-03-30,20:58:41 | INFO |   remote_sync_protocol: s3\n2025-03-30,20:58:41 | INFO |   report_to: \n2025-03-30,20:58:41 | INFO |   resume: None\n2025-03-30,20:58:41 | INFO |   save_frequency: 1\n2025-03-30,20:58:41 | INFO |   save_most_recent: False\n2025-03-30,20:58:41 | INFO |   seed: 42\n2025-03-30,20:58:41 | INFO |   siglip: False\n2025-03-30,20:58:41 | INFO |   skip_scheduler: False\n2025-03-30,20:58:41 | INFO |   soft_temprature: 0.05\n2025-03-30,20:58:41 | INFO |   tensorboard: False\n2025-03-30,20:58:41 | INFO |   tensorboard_path: \n2025-03-30,20:58:41 | INFO |   torchcompile: False\n2025-03-30,20:58:41 | INFO |   torchscript: False\n2025-03-30,20:58:41 | INFO |   trace: False\n2025-03-30,20:58:41 | INFO |   train_data: /kaggle/working/train_data_karpathy.csv\n2025-03-30,20:58:41 | INFO |   train_data_upsampling_factors: None\n2025-03-30,20:58:41 | INFO |   train_num_samples: None\n2025-03-30,20:58:41 | INFO |   use_bn_sync: False\n2025-03-30,20:58:41 | INFO |   use_bnb_linear: None\n2025-03-30,20:58:41 | INFO |   use_dino_reg: True\n2025-03-30,20:58:41 | INFO |   use_soft_labels: False\n2025-03-30,20:58:41 | INFO |   val_data: None\n2025-03-30,20:58:41 | INFO |   val_frequency: 1\n2025-03-30,20:58:41 | INFO |   val_num_samples: None\n2025-03-30,20:58:41 | INFO |   wandb: False\n2025-03-30,20:58:41 | INFO |   wandb_notes: \n2025-03-30,20:58:41 | INFO |   wandb_project_name: open-clip\n2025-03-30,20:58:41 | INFO |   warmup: 1000\n2025-03-30,20:58:41 | INFO |   wd: 0.2\n2025-03-30,20:58:41 | INFO |   workers: 4\n2025-03-30,20:58:41 | INFO |   world_size: 1\n2025-03-30,20:58:41 | INFO |   zeroshot_frequency: 2\n2025-03-30,20:58:41 | INFO | Created AdamW (adamw) optimizer: lr: 5e-06, betas: (0.9, 0.999), eps: 1e-08, weight_decay: 0.2, amsgrad: False, foreach: None, maximize: False, capturable: False, differentiable: False, fused: None\n2025-03-30,20:58:41 | INFO | Start epoch 0\nIt looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n2025-03-30,20:58:47 | INFO | Train Epoch: 0 [    48/145000 (0%)] Data (t): 0.984 Batch (t): 6.184, 7.76254/s, 7.76254/s/gpu LR: 0.000000 Logit Scale: 73.816 Original_clip_loss: 1.7363 (1.7363) Loss: 1.7363 (1.7363) Dino_reguarizing_loss: 0.15132 (0.15132)\n2025-03-30,21:00:35 | INFO | Train Epoch: 0 [  4848/145000 (3%)] Data (t): 0.000 Batch (t): 1.082, 47.6268/s, 47.6268/s/gpu LR: 0.000001 Logit Scale: 73.814 Original_clip_loss: 1.7166 (1.7264) Loss: 1.7166 (1.7264) Dino_reguarizing_loss: 0.18832 (0.16982)\n2025-03-30,21:02:24 | INFO | Train Epoch: 0 [  9648/145000 (7%)] Data (t): 0.001 Batch (t): 1.089, 44.5559/s, 44.5559/s/gpu LR: 0.000001 Logit Scale: 73.809 Original_clip_loss: 1.5936 (1.6821) Loss: 1.5936 (1.6821) Dino_reguarizing_loss: 0.17748 (0.17237)\n2025-03-30,21:04:13 | INFO | Train Epoch: 0 [ 14448/145000 (10%)] Data (t): 0.001 Batch (t): 1.086, 45.0198/s, 45.0198/s/gpu LR: 0.000002 Logit Scale: 73.801 Original_clip_loss: 1.5879 (1.6586) Loss: 1.5879 (1.6586) Dino_reguarizing_loss: 0.14248 (0.16490)\n2025-03-30,21:06:00 | INFO | Train Epoch: 0 [ 19248/145000 (13%)] Data (t): 0.001 Batch (t): 1.073, 45.8456/s, 45.8456/s/gpu LR: 0.000002 Logit Scale: 73.790 Original_clip_loss: 1.8527 (1.6974) Loss: 1.8527 (1.6974) Dino_reguarizing_loss: 0.11747 (0.15541)\n2025-03-30,21:07:48 | INFO | Train Epoch: 0 [ 24048/145000 (17%)] Data (t): 0.001 Batch (t): 1.077, 47.2008/s, 47.2008/s/gpu LR: 0.000003 Logit Scale: 73.776 Original_clip_loss: 1.6619 (1.6915) Loss: 1.6619 (1.6915) Dino_reguarizing_loss: 0.11602 (0.14885)\n2025-03-30,21:09:35 | INFO | Train Epoch: 0 [ 28848/145000 (20%)] Data (t): 0.001 Batch (t): 1.070, 43.6276/s, 43.6276/s/gpu LR: 0.000003 Logit Scale: 73.760 Original_clip_loss: 1.3934 (1.6489) Loss: 1.3934 (1.6489) Dino_reguarizing_loss: 0.083869 (0.13957)\n2025-03-30,21:11:21 | INFO | Train Epoch: 0 [ 33648/145000 (23%)] Data (t): 0.001 Batch (t): 1.058, 41.7070/s, 41.7070/s/gpu LR: 0.000004 Logit Scale: 73.743 Original_clip_loss: 1.0101 (1.5691) Loss: 1.0101 (1.5691) Dino_reguarizing_loss: 0.077645 (0.13183)\n2025-03-30,21:13:06 | INFO | Train Epoch: 0 [ 38448/145000 (27%)] Data (t): 0.001 Batch (t): 1.051, 48.0303/s, 48.0303/s/gpu LR: 0.000004 Logit Scale: 73.723 Original_clip_loss: 1.0845 (1.5152) Loss: 1.0845 (1.5152) Dino_reguarizing_loss: 0.063845 (0.12427)\n2025-03-30,21:14:53 | INFO | Train Epoch: 0 [ 43248/145000 (30%)] Data (t): 0.001 Batch (t): 1.076, 48.8361/s, 48.8361/s/gpu LR: 0.000005 Logit Scale: 73.704 Original_clip_loss: 1.2599 (1.4897) Loss: 1.2599 (1.4897) Dino_reguarizing_loss: 0.060946 (0.11794)\n2025-03-30,21:16:44 | INFO | Train Epoch: 0 [ 48048/145000 (33%)] Data (t): 0.001 Batch (t): 1.109, 44.0776/s, 44.0776/s/gpu LR: 0.000005 Logit Scale: 73.684 Original_clip_loss: 0.82553 (1.4293) Loss: 0.82553 (1.4293) Dino_reguarizing_loss: 0.056498 (0.11235)\n2025-03-30,21:18:34 | INFO | Train Epoch: 0 [ 52848/145000 (36%)] Data (t): 0.001 Batch (t): 1.101, 41.2892/s, 41.2892/s/gpu LR: 0.000005 Logit Scale: 73.665 Original_clip_loss: 1.0238 (1.3955) Loss: 1.0238 (1.3955) Dino_reguarizing_loss: 0.039049 (0.10624)\n2025-03-30,21:20:23 | INFO | Train Epoch: 0 [ 57648/145000 (40%)] Data (t): 0.001 Batch (t): 1.082, 40.9256/s, 40.9256/s/gpu LR: 0.000005 Logit Scale: 73.650 Original_clip_loss: 0.75608 (1.3463) Loss: 0.75608 (1.3463) Dino_reguarizing_loss: 0.043882 (0.10145)\n2025-03-30,21:22:12 | INFO | Train Epoch: 0 [ 62448/145000 (43%)] Data (t): 0.001 Batch (t): 1.092, 43.8568/s, 43.8568/s/gpu LR: 0.000005 Logit Scale: 73.635 Original_clip_loss: 0.77789 (1.3057) Loss: 0.77789 (1.3057) Dino_reguarizing_loss: 0.038535 (0.096954)\n2025-03-30,21:23:59 | INFO | Train Epoch: 0 [ 67248/145000 (46%)] Data (t): 0.001 Batch (t): 1.076, 47.8910/s, 47.8910/s/gpu LR: 0.000005 Logit Scale: 73.622 Original_clip_loss: 0.80668 (1.2725) Loss: 0.80668 (1.2725) Dino_reguarizing_loss: 0.038741 (0.093073)\n2025-03-30,21:25:48 | INFO | Train Epoch: 0 [ 72048/145000 (50%)] Data (t): 0.001 Batch (t): 1.085, 46.3880/s, 46.3880/s/gpu LR: 0.000004 Logit Scale: 73.611 Original_clip_loss: 0.83509 (1.2451) Loss: 0.83509 (1.2451) Dino_reguarizing_loss: 0.028175 (0.089017)\n2025-03-30,21:27:37 | INFO | Train Epoch: 0 [ 76848/145000 (53%)] Data (t): 0.001 Batch (t): 1.095, 41.8657/s, 41.8657/s/gpu LR: 0.000004 Logit Scale: 73.601 Original_clip_loss: 0.84288 (1.2215) Loss: 0.84288 (1.2215) Dino_reguarizing_loss: 0.022263 (0.085090)\n2025-03-30,21:29:25 | INFO | Train Epoch: 0 [ 81648/145000 (56%)] Data (t): 0.001 Batch (t): 1.077, 46.8544/s, 46.8544/s/gpu LR: 0.000004 Logit Scale: 73.592 Original_clip_loss: 0.89707 (1.2034) Loss: 0.89707 (1.2034) Dino_reguarizing_loss: 0.025074 (0.081756)\n2025-03-30,21:31:12 | INFO | Train Epoch: 0 [ 86448/145000 (60%)] Data (t): 0.001 Batch (t): 1.072, 44.5284/s, 44.5284/s/gpu LR: 0.000003 Logit Scale: 73.585 Original_clip_loss: 0.84644 (1.1846) Loss: 0.84644 (1.1846) Dino_reguarizing_loss: 0.025046 (0.078771)\n2025-03-30,21:33:00 | INFO | Train Epoch: 0 [ 91248/145000 (63%)] Data (t): 0.001 Batch (t): 1.079, 45.3125/s, 45.3125/s/gpu LR: 0.000003 Logit Scale: 73.579 Original_clip_loss: 0.40246 (1.1455) Loss: 0.40246 (1.1455) Dino_reguarizing_loss: 0.032364 (0.076451)\n2025-03-30,21:34:48 | INFO | Train Epoch: 0 [ 96048/145000 (66%)] Data (t): 0.001 Batch (t): 1.083, 45.3030/s, 45.3030/s/gpu LR: 0.000003 Logit Scale: 73.574 Original_clip_loss: 0.58886 (1.1190) Loss: 0.58886 (1.1190) Dino_reguarizing_loss: 0.025911 (0.074044)\n2025-03-30,21:36:35 | INFO | Train Epoch: 0 [100848/145000 (70%)] Data (t): 0.001 Batch (t): 1.069, 39.7177/s, 39.7177/s/gpu LR: 0.000002 Logit Scale: 73.569 Original_clip_loss: 0.71203 (1.1005) Loss: 0.71203 (1.1005) Dino_reguarizing_loss: 0.023917 (0.071766)\n2025-03-30,21:38:24 | INFO | Train Epoch: 0 [105648/145000 (73%)] Data (t): 0.001 Batch (t): 1.086, 45.2069/s, 45.2069/s/gpu LR: 0.000002 Logit Scale: 73.566 Original_clip_loss: 0.64018 (1.0805) Loss: 0.64018 (1.0805) Dino_reguarizing_loss: 0.023432 (0.069664)\n2025-03-30,21:40:12 | INFO | Train Epoch: 0 [110448/145000 (76%)] Data (t): 0.001 Batch (t): 1.084, 45.9289/s, 45.9289/s/gpu LR: 0.000001 Logit Scale: 73.562 Original_clip_loss: 0.66925 (1.0634) Loss: 0.66925 (1.0634) Dino_reguarizing_loss: 0.019156 (0.067560)\n2025-03-30,21:42:02 | INFO | Train Epoch: 0 [115248/145000 (80%)] Data (t): 0.001 Batch (t): 1.101, 46.2047/s, 46.2047/s/gpu LR: 0.000001 Logit Scale: 73.560 Original_clip_loss: 0.86840 (1.0556) Loss: 0.86840 (1.0556) Dino_reguarizing_loss: 0.021368 (0.065712)\n2025-03-30,21:43:52 | INFO | Train Epoch: 0 [120048/145000 (83%)] Data (t): 0.001 Batch (t): 1.092, 46.3713/s, 46.3713/s/gpu LR: 0.000001 Logit Scale: 73.558 Original_clip_loss: 0.57898 (1.0373) Loss: 0.57898 (1.0373) Dino_reguarizing_loss: 0.019915 (0.063951)\n2025-03-30,21:45:40 | INFO | Train Epoch: 0 [124848/145000 (86%)] Data (t): 0.001 Batch (t): 1.082, 46.6446/s, 46.6446/s/gpu LR: 0.000001 Logit Scale: 73.558 Original_clip_loss: 0.82525 (1.0294) Loss: 0.82525 (1.0294) Dino_reguarizing_loss: 0.019955 (0.062321)\n2025-03-30,21:47:29 | INFO | Train Epoch: 0 [129648/145000 (89%)] Data (t): 0.001 Batch (t): 1.089, 40.9764/s, 40.9764/s/gpu LR: 0.000000 Logit Scale: 73.558 Original_clip_loss: 0.66353 (1.0163) Loss: 0.66353 (1.0163) Dino_reguarizing_loss: 0.020001 (0.060810)\n2025-03-30,21:49:18 | INFO | Train Epoch: 0 [134448/145000 (93%)] Data (t): 0.001 Batch (t): 1.093, 44.0456/s, 44.0456/s/gpu LR: 0.000000 Logit Scale: 73.558 Original_clip_loss: 1.0291 (1.0168) Loss: 1.0291 (1.0168) Dino_reguarizing_loss: 0.017819 (0.059327)\n2025-03-30,21:51:05 | INFO | Train Epoch: 0 [139248/145000 (96%)] Data (t): 0.001 Batch (t): 1.074, 47.3612/s, 47.3612/s/gpu LR: 0.000000 Logit Scale: 73.558 Original_clip_loss: 0.76875 (1.0085) Loss: 0.76875 (1.0085) Dino_reguarizing_loss: 0.023603 (0.058137)\n2025-03-30,21:52:56 | INFO | Train Epoch: 0 [144048/145000 (99%)] Data (t): 0.001 Batch (t): 1.106, 41.1441/s, 41.1441/s/gpu LR: 0.000000 Logit Scale: 73.558 Original_clip_loss: 0.62386 (0.99610) Loss: 0.62386 (0.99610) Dino_reguarizing_loss: 0.016560 (0.056795)\n2025-03-30,21:53:16 | INFO | Train Epoch: 0 [144960/145000 (100%)] Data (t): 0.003 Batch (t): 1.073, 46.8535/s, 46.8535/s/gpu LR: 0.000000 Logit Scale: 73.558 Original_clip_loss: 0.69853 (0.98680) Loss: 0.69853 (0.98680) Dino_reguarizing_loss: 0.020765 (0.055669)\nI0330 21:53:18.809000 684 torch/_dynamo/utils.py:399] TorchDynamo compilation metrics:\nI0330 21:53:18.809000 684 torch/_dynamo/utils.py:399] Function    Runtimes (s)\nI0330 21:53:18.809000 684 torch/_dynamo/utils.py:399] ----------  --------------\nI0330 21:53:18.814000 684 torch/_subclasses/fake_tensor.py:2423] FakeTensor cache stats:\nI0330 21:53:18.814000 684 torch/_subclasses/fake_tensor.py:2424]   cache_hits: 0\nI0330 21:53:18.815000 684 torch/_subclasses/fake_tensor.py:2425]   cache_misses: 0\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"#!rm -rf checkpoints/dino_fine_tuned_Clip_1_epoch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T20:58:29.267581Z","iopub.execute_input":"2025-03-30T20:58:29.267908Z","iopub.status.idle":"2025-03-30T20:58:29.446313Z","shell.execute_reply.started":"2025-03-30T20:58:29.267882Z","shell.execute_reply":"2025-03-30T20:58:29.445061Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"# Path to your trained checkpoint\ncheckpoint_path = \"checkpoints/dino_fine_tuned_Clip_1_epoch/checkpoints/epoch_1.pt\"\n\n# 1. Create the model architecture from scratch (without loading pretrained weights)\nmodel_dino_fine_tuned_Clip_1_epoch, preprocess_ft, preprocess_val = open_clip.create_model_and_transforms(\n    \"RN50\", pretrained=None\n)\n\n# 2. Load the trained checkpoint manually\ncheckpoint = torch.load(checkpoint_path, map_location=\"cpu\",weights_only=True)\n\n# If the state_dict is nested under a key (like \"state_dict\"), adjust accordingly\nif \"state_dict\" in checkpoint:\n    checkpoint = checkpoint[\"state_dict\"]\n\n# Load checkpoint weights into model\nmodel_dino_fine_tuned_Clip_1_epoch.load_state_dict(checkpoint, strict=False)  # Use strict=False to avoid missing keys error\n\n# 3. Move model to GPU (if available)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel_dino_fine_tuned_Clip_1_epoch = model_dino_fine_tuned_Clip_1_epoch.to(device)\nmodel_dino_fine_tuned_Clip_1_epoch.eval()\nprint(\"Model loaded successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T22:03:09.853711Z","iopub.execute_input":"2025-03-30T22:03:09.854046Z","iopub.status.idle":"2025-03-30T22:03:12.200533Z","shell.execute_reply.started":"2025-03-30T22:03:09.854017Z","shell.execute_reply":"2025-03-30T22:03:12.199576Z"}},"outputs":[{"name":"stdout","text":"Model loaded successfully!\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"/kaggle/working/cyclip_checkpoints\", 'zip', \"/kaggle/working/checkpoints\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T21:59:35.266868Z","iopub.execute_input":"2025-03-30T21:59:35.267275Z","iopub.status.idle":"2025-03-30T22:01:21.536545Z","shell.execute_reply.started":"2025-03-30T21:59:35.267241Z","shell.execute_reply":"2025-03-30T22:01:21.535332Z"}},"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/cyclip_checkpoints.zip'"},"metadata":{}}],"execution_count":88},{"cell_type":"code","source":"#      EVALUATING BELOW","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = [item for item in karpathy_data[\"images\"] if item[\"split\"] == \"test\"]\nall_captions = []\nall_images = []\nfor item in test_data:\n    for sentence in item[\"sentences\"]:\n        all_captions.append(sentence[\"raw\"])\n        all_images.append(item[\"filename\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:49:02.136873Z","iopub.execute_input":"2025-03-30T19:49:02.137098Z","iopub.status.idle":"2025-03-30T19:49:02.165035Z","shell.execute_reply.started":"2025-03-30T19:49:02.137079Z","shell.execute_reply":"2025-03-30T19:49:02.164199Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# Compute embeddings\n#FROM CYCLIP\n\nimage_root = \"/kaggle/input/flickr30k/Images\"\ntext_embeds, image_embeds = get_all_embeddings(\n    model_Cyclip_final, all_captions, all_images, root=image_root,\n    preprocess=preprocess, tokenizer=tokenizer, device=device , batch_size=48\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:49:34.094639Z","iopub.execute_input":"2025-03-30T19:49:34.094966Z","iopub.status.idle":"2025-03-30T19:50:51.657167Z","shell.execute_reply.started":"2025-03-30T19:49:34.094941Z","shell.execute_reply":"2025-03-30T19:50:51.656236Z"}},"outputs":[{"name":"stderr","text":"Encoding batches: 100%|██████████| 105/105 [01:17<00:00,  1.35it/s]\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"#FROM CYCLIP\n# Evaluate\nresults = itm_eval(text_embeds, image_embeds)\nprint(\"📊 Evaluation Results:\")\nfor k, v in results.items():\n    print(f\"{k}: {v:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:51:52.494705Z","iopub.execute_input":"2025-03-30T19:51:52.495025Z","iopub.status.idle":"2025-03-30T19:51:53.784858Z","shell.execute_reply.started":"2025-03-30T19:51:52.495002Z","shell.execute_reply":"2025-03-30T19:51:53.783814Z"}},"outputs":[{"name":"stdout","text":"📊 Evaluation Results:\ntxt_r1: 88.24\ntxt_r5: 94.00\ntxt_r10: 96.00\ntxt_r_mean: 92.75\nimg_r1: 30.42\nimg_r5: 57.10\nimg_r10: 68.82\nimg_r_mean: 52.11\nr_mean: 72.43\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"image_root = \"/kaggle/input/flickr30k/Images\"\ntext_embeds, image_embeds = get_all_embeddings(\n    model_clip_final, all_captions, all_images, root=image_root,\n    preprocess=preprocess, tokenizer=tokenizer, device=device , batch_size=48\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:51:53.786276Z","iopub.execute_input":"2025-03-30T19:51:53.786645Z","iopub.status.idle":"2025-03-30T19:53:01.967040Z","shell.execute_reply.started":"2025-03-30T19:51:53.786608Z","shell.execute_reply":"2025-03-30T19:53:01.966193Z"}},"outputs":[{"name":"stderr","text":"Encoding batches: 100%|██████████| 105/105 [01:08<00:00,  1.54it/s]\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"#FROM CYCLIP\n# Evaluate\nresults = itm_eval(text_embeds, image_embeds)\nprint(\"📊 Evaluation Results:\")\nfor k, v in results.items():\n    print(f\"{k}: {v:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T19:53:01.968689Z","iopub.execute_input":"2025-03-30T19:53:01.968943Z","iopub.status.idle":"2025-03-30T19:53:03.207792Z","shell.execute_reply.started":"2025-03-30T19:53:01.968922Z","shell.execute_reply":"2025-03-30T19:53:03.206949Z"}},"outputs":[{"name":"stdout","text":"📊 Evaluation Results:\ntxt_r1: 88.10\ntxt_r5: 93.84\ntxt_r10: 95.90\ntxt_r_mean: 92.61\nimg_r1: 30.54\nimg_r5: 56.92\nimg_r10: 68.26\nimg_r_mean: 51.91\nr_mean: 72.26\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"#FOR FINE TUNED CLIP","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute embeddings\n\nimage_root = \"/kaggle/input/flickr30k/Images\"\ntext_embeds, image_embeds = get_all_embeddings(\n    model_og_fine_tuned_Clip_1_epoch, all_captions, all_images, root=image_root,\n    preprocess=preprocess, tokenizer=tokenizer, device=device , batch_size=48\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T22:04:20.883460Z","iopub.execute_input":"2025-03-30T22:04:20.883839Z","iopub.status.idle":"2025-03-30T22:05:27.979593Z","shell.execute_reply.started":"2025-03-30T22:04:20.883808Z","shell.execute_reply":"2025-03-30T22:05:27.978915Z"}},"outputs":[{"name":"stderr","text":"Encoding batches: 100%|██████████| 105/105 [01:07<00:00,  1.57it/s]\n","output_type":"stream"}],"execution_count":91},{"cell_type":"code","source":"# Evaluate\nresults = itm_eval(text_embeds, image_embeds)\nprint(\"📊 Evaluation Results:\")\nfor k, v in results.items():\n    print(f\"{k}: {v:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T22:07:17.470833Z","iopub.execute_input":"2025-03-30T22:07:17.471193Z","iopub.status.idle":"2025-03-30T22:07:18.658910Z","shell.execute_reply.started":"2025-03-30T22:07:17.471167Z","shell.execute_reply":"2025-03-30T22:07:18.657986Z"}},"outputs":[{"name":"stdout","text":"📊 Evaluation Results:\ntxt_r1: 90.02\ntxt_r5: 95.62\ntxt_r10: 97.26\ntxt_r_mean: 94.30\nimg_r1: 36.06\nimg_r5: 65.32\nimg_r10: 75.84\nimg_r_mean: 59.07\nr_mean: 76.69\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"image_root = \"/kaggle/input/flickr30k/Images\"\ntext_embeds, image_embeds = get_all_embeddings(\n    model_dino_fine_tuned_Clip_1_epoch, all_captions, all_images, root=image_root,\n    preprocess=preprocess, tokenizer=tokenizer, device=device , batch_size=48\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T22:08:47.426704Z","iopub.execute_input":"2025-03-30T22:08:47.427068Z","iopub.status.idle":"2025-03-30T22:09:55.219866Z","shell.execute_reply.started":"2025-03-30T22:08:47.427039Z","shell.execute_reply":"2025-03-30T22:09:55.219148Z"}},"outputs":[{"name":"stderr","text":"Encoding batches: 100%|██████████| 105/105 [01:07<00:00,  1.55it/s]\n","output_type":"stream"}],"execution_count":94},{"cell_type":"code","source":"# Evaluate\nresults = itm_eval(text_embeds, image_embeds)\nprint(\"📊 Evaluation Results:\")\nfor k, v in results.items():\n    print(f\"{k}: {v:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T22:09:56.271360Z","iopub.execute_input":"2025-03-30T22:09:56.271641Z","iopub.status.idle":"2025-03-30T22:09:57.426479Z","shell.execute_reply.started":"2025-03-30T22:09:56.271619Z","shell.execute_reply":"2025-03-30T22:09:57.425732Z"}},"outputs":[{"name":"stdout","text":"📊 Evaluation Results:\ntxt_r1: 89.98\ntxt_r5: 95.54\ntxt_r10: 97.22\ntxt_r_mean: 94.25\nimg_r1: 36.34\nimg_r5: 65.74\nimg_r10: 76.02\nimg_r_mean: 59.37\nr_mean: 76.81\n","output_type":"stream"}],"execution_count":95},{"cell_type":"code","source":"# CONSISTENCY METRICS BELOW","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_records = []\nfor item in test_data:\n    img_filename = f\"/kaggle/input/flickr30k/Images/{item['filename']}\"\n    for sentence in item[\"sentences\"]:\n        caption = sentence[\"raw\"]\n        test_records.append({\"image\": img_filename, \"caption\": caption})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T22:14:25.613898Z","iopub.execute_input":"2025-03-30T22:14:25.614316Z","iopub.status.idle":"2025-03-30T22:14:25.628473Z","shell.execute_reply.started":"2025-03-30T22:14:25.614273Z","shell.execute_reply":"2025-03-30T22:14:25.627662Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass CyCLIPDataset(Dataset):\n    def __init__(self, records, image_transform):\n        self.records = records\n        self.image_transform = image_transform\n\n    def __len__(self):\n        return len(self.records)\n\n    def __getitem__(self, idx):\n        record = self.records[idx]\n        image = self.image_transform(Image.open(record[\"image\"]).convert(\"RGB\"))\n        text = tokenizer(record[\"caption\"]).squeeze(0)  # remove batch dim\n        return image, text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T22:15:14.878291Z","iopub.execute_input":"2025-03-30T22:15:14.878576Z","iopub.status.idle":"2025-03-30T22:15:14.883649Z","shell.execute_reply.started":"2025-03-30T22:15:14.878554Z","shell.execute_reply":"2025-03-30T22:15:14.882803Z"}},"outputs":[],"execution_count":109},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntest_dataset = CyCLIPDataset(test_records, preprocess)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T22:15:20.256070Z","iopub.execute_input":"2025-03-30T22:15:20.256388Z","iopub.status.idle":"2025-03-30T22:15:20.260569Z","shell.execute_reply.started":"2025-03-30T22:15:20.256364Z","shell.execute_reply":"2025-03-30T22:15:20.259760Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"# compute_consistency_score calculate mean of similarities\n\n# CLIP final with og Fine tuning\n\nscore = compute_consistency_score(model_dino_fine_tuned_Clip_1_epoch, test_loader, device)\n\nprint(f\"Consistency Score: {score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T22:15:21.685927Z","iopub.execute_input":"2025-03-30T22:15:21.686273Z","iopub.status.idle":"2025-03-30T22:16:29.612784Z","shell.execute_reply.started":"2025-03-30T22:15:21.686243Z","shell.execute_reply":"2025-03-30T22:16:29.612049Z"}},"outputs":[{"name":"stdout","text":"Consistency Score: 0.4355\n","output_type":"stream"}],"execution_count":112},{"cell_type":"code","source":"# CLIP final with og Fine tuning\n\nscore = compute_consistency_score(model_og_fine_tuned_Clip_1_epoch, test_loader, device)\n\nprint(f\"Consistency Score: {score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T22:16:44.438932Z","iopub.execute_input":"2025-03-30T22:16:44.439270Z","iopub.status.idle":"2025-03-30T22:17:52.995227Z","shell.execute_reply.started":"2025-03-30T22:16:44.439243Z","shell.execute_reply":"2025-03-30T22:17:52.994435Z"}},"outputs":[{"name":"stdout","text":"Consistency Score: 0.4334\n","output_type":"stream"}],"execution_count":113},{"cell_type":"code","source":"# CLIP final\n\nscore = compute_consistency_score(model_clip_final, test_loader, device)\n\nprint(f\"Consistency Score: {score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T22:30:40.792458Z","iopub.execute_input":"2025-03-30T22:30:40.792732Z","iopub.status.idle":"2025-03-30T22:31:48.043220Z","shell.execute_reply.started":"2025-03-30T22:30:40.792710Z","shell.execute_reply":"2025-03-30T22:31:48.042385Z"}},"outputs":[{"name":"stdout","text":"Consistency Score: 0.0070\n","output_type":"stream"}],"execution_count":117},{"cell_type":"code","source":"# CYCLIP final \n\nscore = compute_consistency_score(model_Cyclip_final, test_loader, device)\n\nprint(f\"Consistency Score: {score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T22:29:32.494178Z","iopub.execute_input":"2025-03-30T22:29:32.494462Z","iopub.status.idle":"2025-03-30T22:30:40.791519Z","shell.execute_reply.started":"2025-03-30T22:29:32.494441Z","shell.execute_reply":"2025-03-30T22:30:40.790764Z"}},"outputs":[{"name":"stdout","text":"Consistency Score: -0.0388\n","output_type":"stream"}],"execution_count":116}]}